{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arxiv_paper_summarizer import ArxivPaperSummarizer\n",
    "\n",
    "arxiv_url = \"https://arxiv.org/abs/2401.18059\"\n",
    "paper_summarizer = ArxivPaperSummarizer(arxiv_url=arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ABSTRACT'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Retrieval-augmented language models can better adapt to changes in world state and incorporate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limiting holistic understanding of the overall document context. We introduce the novel approach of recursively </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">20% in absolute accuracy.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'figure-1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1 INTRODUCTION'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Large Language Models (LLMs) have emerged as transformative tools showing impressive performance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on many tasks. With the growing size of LLMs, they can serve standalone as very effective knowledge stores, with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facts encoded within their parameters (Petroni et al., 2019; Jiang et al., 2020; Talmor et al., 2020; Rae et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021; Hoffmann et al., 2022; Chowdhery et al., 2022; Bubeck et al., 2023; Kandpal et al., 2023) and models can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">further improved with fine-tuning on downstream tasks (Roberts et al., 2020). Nevertheless, even a large model does</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not contain sufficient domain-specific knowledge for particular tasks and the world continues to change, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">invalidating facts in the LLM. Updating the knowledge of these models through additional fine-tuning or editing is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">difficult, particularly when dealing with vast text corpora (Lewis et al., 2020; Mitchell et al., 2022). An </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">alternative approach, pioneered in open domain question answering systems (Chen et al., 2017; Yu et al., 2018), is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to index large quantities of text, after splitting it into chunks (paragraphs), in a separate information retrieval</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system. Retrieved information is then presented to the LLM along with the question as context (“retrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">augmentation”, Lewis et al., 2020; Izacard et al., 2022; Min et al., 2023; Ram et al., 2023), making it easy to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide a system with current knowledge particular to some domain and enabling easy interpretability and provenance</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tracking, whereas the parametric knowledge of LLMs is opaque and difficult to trace back to its source (Akyurek et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2022). Nevertheless, existing retrieval-augmented approaches also have flaws. The one we tackle is that most </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">existing methods retrieve only a few short, contiguous text chunks, which limits their ability to represent and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leverage large-scale discourse structure. This is particularly relevant for thematic questions that require </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">integrating knowledge from multiple parts of a text, such as understanding an entire book, as in the NarrativeQA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset (Koˇcisk`y et al., 2018). Consider the fairy tale of Cinderella, and the question “How did Cinderella reach</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her happy ending?”. The top-k retrieved short contiguous texts will not contain enough context to answer the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question. To address this, we design an indexing and retrieval system that uses a tree structure to capture both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">high-level and low-level details about a text. As shown in Figure 1, our system, RAPTOR, clusters chunks of text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generates text summaries of those clusters, and then repeats, generating a tree from the bottom up. This structure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enables RAPTOR to load into an LLM’s context chunks representing the text at different levels so that it can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively and efficiently answer questions at different levels.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'figure-1'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2 RELATED WORK'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why Retrieval? Recent advances in hardware and algorithms have indeed expanded the con-text </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lengths that models can handle, leading to questions about the need for retrieval systems (Dai et al., 2019; Dao et</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2022; Liu et al., 2023). However, as Liu et al. (2023) and Sun et al. (2021) have noted, models tend to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">underutilize long-range context and see diminishing performance as con-text length increases, especially when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pertinent information is embedded within a lengthy context. Moreover, practically, use of long contexts is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expensive and slow. This suggests that selecting the most relevant information for knowledge-intensive tasks is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">still crucial. Retrieval Methods Retrieval-augmented language models (RALMs) have seen improvements in various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components: the retriever, the reader, and end-to-end system training. Retrieval methods have transitioned from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional term-based techniques like TF-IDF (Sp¨arck Jones, 1972) and BM25 (Robertson et al., 1995; Roberts et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2020) to deep learning–based strategies (Karpukhin et al., 2020; Khattab &amp; Zaharia, 2020; Sachan et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023). Some recent work proposes using large language models as retrievers due to their ability to memorize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extensive knowledge (Yu et al., 2022; Sun et al., 2022). Research on the reader component includes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fusion-in-Decoder (FiD) (Izacard &amp; Grave, 2022), which employs both DPR and BM25 for retrieval and processes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">passages independently in the encoder and RETRO (Borgeaud et al., 2022; Wang et al., 2023), which utilizes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cross-chunked attention and chunkwise retrieval to generate text grounded on retrieved context. End-to-end system </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training work includes Atlas (Izacard et al., 2022), which fine-tunes an encoder-decoder model in conjunction with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the retriever; REALM (Guu et al., 2020), a bidirectional, masked LM fine-tuned for open-domain question answering; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and RAG (Retrieval-Augmented Genera-tion) (Lewis et al., 2020), which integrates pre-trained sequence-to-sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models with a neural retriever. Min et al. (2021) introduced Joint Passage Retrieval (JPR) model which uses a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tree-decoding algorithm to handle passage diversity and relevance in multi-answer retrieval. Dense Hi-erarchical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval (DHR) and Hybrid Hierarchical Retrieval (HHR) represent advancements in retrieval accuracy by combining </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document and passage level retrievals and integrating sparse and dense retrieval methods, respectively (Liu et al.,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021; Arivazhagan et al., 2023). Despite a diversity in methods, the retrieving components of models predominantly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rely on stan-dard approaches, i.e., chunking corpora and encoding with BERT-based retrievers. Although this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach is widely adopted, Nair et al. (2023) highlights a potential shortcoming: contiguous seg-mentation might </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not capture the complete semantic depth of the text. Reading extracted snippets from technical or scientific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documents may lack important context making them difficult to read or even misleading. (Cohan &amp; Goharian, 2017; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Newman et al., 2023; Zhang et al., 2023). Recursive summarization as Context Summarization techniques provide a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">condensed view of documents, enabling more focused engagement with the content (Angelidis &amp; Lapata, 2018). The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization/snippet model by Gao et al. (2023) uses summarizations and snippets of passages, which improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">correctness on most datasets but can sometimes be a lossy means of compression. The recursive-abstractive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization model by Wu et al. (2021) employs task decomposition to summarize smaller text chunks, which are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">later integrated to form summaries of larger sections. While this method is effective for capturing broader themes,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it can miss granular details. LlamaIndex (Liu, 2022) mitigates this issue by similarly summarizing adjacent text </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chunks but also retaining intermediate nodes thus storing varying levels of detail, keeping granular details. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">However, both methods, due to their reliance on adjacency for grouping or summarizing adjacent nodes, may still </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overlook distant interdependencies within the text, which we can find and group with RAPTOR.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3 METHODS'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi-cal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structures (Cao &amp; Wang, 2022; Dong et al., 2023b), RAPTOR addresses the issue of semantic depth and connection in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reading by building a recursive tree structure that balances broader thematic comprehension with granular details </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and which allows nodes to be grouped based on semantic sim-ilarity not just order in the text. Construction of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR tree begins with segmenting the retrieval corpus into short, contiguous texts of length 100, similar to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional retrieval augmentation techniques. If a sentence exceeds the 100-token limit, we move the entire </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sentence to the next chunk, rather than cutting it mid-sentence. This preserves the contextual and semantic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherence of the text within each chunk. These texts are then embedded using SBERT, a BERT-based encoder </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(multi-qa-mpnet-base-cos-v1) (Reimers &amp; Gurevych, 2019). The chunks and their corresponding SBERT embeddings form </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the leaf nodes of our tree structure. To group similar text chunks, we employ a clustering algorithm. Once </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustered, a Language Model is used to summarize the grouped texts. These summarized texts are then re-embedded, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and the cycle of embedding, clustering, and summarization continues until further clustering becomes infeasible, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">resulting in a structured, multi-layered tree representation of the original documents. An important aspect of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR is its computational efficiency. The system scales linearly in terms of both build time and token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expenditure, making it suitable for processing large and complex corpora. For a comprehensive discussion on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR’s scalability, please refer to the Appendix A. For querying within this tree, we introduce two distinct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strategies: tree traversal and collapsed tree. The tree traversal method traverses the tree layer-by-layer, pruning</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and selecting the most relevant nodes at each level. The collapsed tree method evaluates nodes collectively across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">all layers to find the most relevant ones.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3.1 Clustering Algorithm'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">groups. This step groups related content together, which helps the subsequent retrieval process. One of the unique </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspects of our clustering approach is the use of soft clustering, where nodes can belong to multiple clusters </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">without requiring a fixed number of clusters. This flexibility is essen-tial because individual text segments often</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contain information relevant to various topics, thereby warranting their inclusion in multiple summaries. Our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering algorithm is based on Gaussian Mixture Models (GMMs), an approach that offers both flexibility and a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probabilistic framework. GMMs assume that data points are generated from a mixture of several Gaussian </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distributions. Given a set of N text segments, each represented as a d-dimensional dense vector embedding, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">likelihood of a text vector, x, given its membership in the kth Gaussian distribution, is denoted by P(x|k) = N(x; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">µk, Σk). The overall probability distribution is a weighted combination P(x) = PK k=1 πkN(x; µk, Σk), where πk </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">signifies the mixture weight for the kth Gaussian distribution. The high dimensionality of vector embeddings </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">presents a challenge for traditional GMMs, as dis-tance metrics may behave poorly when used to measure similarity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in high-dimensional spaces (Ag-garwal et al., 2001). To mitigate this, we employ Uniform Manifold Approximation and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Projection (UMAP), a manifold learning technique for dimensionality reduction (McInnes et al., 2018). The number of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nearest neighbors parameter, n neighbors, in UMAP determines the balance between the preservation of local and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">global structures. Our algorithm varies n neighbors to create a hierar-chical clustering structure: it first </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identifies global clusters and then performs local clustering within these global clusters. This two-step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering process captures a broad spectrum of relationships among the text data, from broad themes to specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details. Should a local cluster’s combined context ever exceed the summarization model’s token threshold, our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithm recursively applies clustering within the cluster, ensuring that the context remains within the token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">threshold. To determine the optimal number of clusters, we employ the Bayesian Information Criterion (BIC) for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model selection. BIC not only penalizes model complexity but also rewards goodness of fit (Schwarz, 1978). The BIC </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for a given GMM is BIC = ln(N)k −2 ln(ˆL), where N is the number of text segments (or data points), k is the number</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of model parameters, and ˆL is the maximized value of the likelihood function of the model. In the context of GMM, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the number of parameters k is a function of the dimensionality of the input vectors and the number of clusters. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">With the optimal number of clusters determined by BIC, the Expectation-Maximization algorithm is then used to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimate the GMM parameters, namely the means, covariances, and mixture weights. While the Gaussian assumption in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GMMs may not perfectly align with the nature of text data, which often exhibits a sparse and skewed distribution, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our empirical observations suggest that it offers an effective model for our purpose. We run an ablation comparing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GMM Clustering with summarizing contiguous chunks and provide details in Appendix B.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3.2 Model-Based Summarization'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'After clustering the nodes using Gaussian Mixture Models, the nodes in each cluster are sent to a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language model for summarization. This step allows the model to transform large chunks of text into concise, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent summaries of the selected nodes. For our experiments, we use gpt-3.5-turbo to generate the summaries. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization step con-denses the potentially large volume of retrieved information into a manageable size. We </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide statistics on the compression due to the summarization in Appendix C and the prompt used for summarization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Appendix D. While the summarization model generally produces reliable summaries, a focused annotation study </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">revealed that about 4% of the summaries contained minor hallucinations. These did not propagate to parent nodes and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">had no discernible impact on question-answering tasks. For an in-depth analysis of hallucinations, refer to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appendix E.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4 EXPERIMENTS'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Datasets We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">QASPER, and QuALITY. NarrativeQA is a dataset that comprises question-answer pairs based on the full texts of books</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and movie transcripts, totaling 1,572 documents (Koˇcisk`y et al., 2018; Wu et al., 2021). The NarrativeQA-Story </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task requires a comprehensive understanding of the entire narrative in order to accurately answer its questions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thus testing the model’s ability to comprehend longer texts in the literary domain. We measure performance on this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset using the standard BLEU (B-1, B-4), ROUGE (R-L), and METEOR (M) metrics. Please see appendix H for more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details on the Narra-tiveQA evaluation script used in our experiments. The QASPER dataset includes 5,049 questions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across 1,585 NLP papers, with each question probing for information embedded within the full text (Dasigi et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021). The answer types in QASPER are categorized as Answerable/Unanswerable, Yes/No, Abstractive, and Extractive. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Accuracy is measured using standard F1. Lastly, the QuALITY dataset consists of multiple-choice questions, each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accompanied by context passages averaging approximately 5,000 tokens in length (Pang et al., 2022). This dataset </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calls for reasoning over the entire document for QA tasks, enabling us to measure the performance of our re-trieval</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system on medium-length documents. The dataset includes a challenging subset, QuALITY-HARD, which contains </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions that a majority of human annotators answered incorrectly in a speed-setting. We report accuracies for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">both the entire test set and the HARD subset.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ExtractedSectionResult</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">section</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5 CONCLUSION'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In this paper, we have presented RAPTOR, a novel tree-based retrieval system that augments the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parametric knowledge of large language models with contextual information at various levels of abstraction. By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">employing recursive clustering and summarization techniques, RAPTOR creates a hierarchical tree structure that is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capable of synthesizing information across various sections of the retrieval corpora. During the query phase, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR leverages this tree structure for more effective retrieval. Our controlled experiments demonstrated that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR not only outperforms traditional retrieval methods but also sets new performance benchmarks on several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering tasks.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_fig</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">ref_tb</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'ABSTRACT'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Retrieval-augmented language models can better adapt to changes in world state and incorporate \u001b[0m\n",
       "\u001b[32mlong-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, \u001b[0m\n",
       "\u001b[32mlimiting holistic understanding of the overall document context. We introduce the novel approach of recursively \u001b[0m\n",
       "\u001b[32membedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization \u001b[0m\n",
       "\u001b[32mfrom the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across \u001b[0m\n",
       "\u001b[32mlengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive \u001b[0m\n",
       "\u001b[32msummaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On \u001b[0m\n",
       "\u001b[32mquestion-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example,\u001b[0m\n",
       "\u001b[32mby coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by\u001b[0m\n",
       "\u001b[32m20% in absolute accuracy.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'figure-1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'1 INTRODUCTION'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have emerged as transformative tools showing impressive performance \u001b[0m\n",
       "\u001b[32mon many tasks. With the growing size of LLMs, they can serve standalone as very effective knowledge stores, with \u001b[0m\n",
       "\u001b[32mfacts encoded within their parameters \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPetroni et al., 2019; Jiang et al., 2020; Talmor et al., 2020; Rae et al., \u001b[0m\n",
       "\u001b[32m2021; Hoffmann et al., 2022; Chowdhery et al., 2022; Bubeck et al., 2023; Kandpal et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and models can be \u001b[0m\n",
       "\u001b[32mfurther improved with fine-tuning on downstream tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRoberts et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Nevertheless, even a large model does\u001b[0m\n",
       "\u001b[32mnot contain sufficient domain-specific knowledge for particular tasks and the world continues to change, \u001b[0m\n",
       "\u001b[32minvalidating facts in the LLM. Updating the knowledge of these models through additional fine-tuning or editing is \u001b[0m\n",
       "\u001b[32mdifficult, particularly when dealing with vast text corpora \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLewis et al., 2020; Mitchell et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. An \u001b[0m\n",
       "\u001b[32malternative approach, pioneered in open domain question answering systems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mChen et al., 2017; Yu et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, is \u001b[0m\n",
       "\u001b[32mto index large quantities of text, after splitting it into chunks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mparagraphs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, in a separate information retrieval\u001b[0m\n",
       "\u001b[32msystem. Retrieved information is then presented to the LLM along with the question as context \u001b[0m\u001b[32m(\u001b[0m\u001b[32m“retrieval \u001b[0m\n",
       "\u001b[32maugmentation”, Lewis et al., 2020; Izacard et al., 2022; Min et al., 2023; Ram et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, making it easy to \u001b[0m\n",
       "\u001b[32mprovide a system with current knowledge particular to some domain and enabling easy interpretability and provenance\u001b[0m\n",
       "\u001b[32mtracking, whereas the parametric knowledge of LLMs is opaque and difficult to trace back to its source \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAkyurek et \u001b[0m\n",
       "\u001b[32mal., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Nevertheless, existing retrieval-augmented approaches also have flaws. The one we tackle is that most \u001b[0m\n",
       "\u001b[32mexisting methods retrieve only a few short, contiguous text chunks, which limits their ability to represent and \u001b[0m\n",
       "\u001b[32mleverage large-scale discourse structure. This is particularly relevant for thematic questions that require \u001b[0m\n",
       "\u001b[32mintegrating knowledge from multiple parts of a text, such as understanding an entire book, as in the NarrativeQA \u001b[0m\n",
       "\u001b[32mdataset \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKoˇcisk`y et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consider the fairy tale of Cinderella, and the question “How did Cinderella reach\u001b[0m\n",
       "\u001b[32mher happy ending?”. The top-k retrieved short contiguous texts will not contain enough context to answer the \u001b[0m\n",
       "\u001b[32mquestion. To address this, we design an indexing and retrieval system that uses a tree structure to capture both \u001b[0m\n",
       "\u001b[32mhigh-level and low-level details about a text. As shown in Figure 1, our system, RAPTOR, clusters chunks of text, \u001b[0m\n",
       "\u001b[32mgenerates text summaries of those clusters, and then repeats, generating a tree from the bottom up. This structure \u001b[0m\n",
       "\u001b[32menables RAPTOR to load into an LLM’s context chunks representing the text at different levels so that it can \u001b[0m\n",
       "\u001b[32meffectively and efficiently answer questions at different levels.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'figure-1'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'2 RELATED WORK'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Why Retrieval? Recent advances in hardware and algorithms have indeed expanded the con-text \u001b[0m\n",
       "\u001b[32mlengths that models can handle, leading to questions about the need for retrieval systems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDai et al., 2019; Dao et\u001b[0m\n",
       "\u001b[32mal., 2022; Liu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. However, as Liu et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Sun et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have noted, models tend to \u001b[0m\n",
       "\u001b[32munderutilize long-range context and see diminishing performance as con-text length increases, especially when \u001b[0m\n",
       "\u001b[32mpertinent information is embedded within a lengthy context. Moreover, practically, use of long contexts is \u001b[0m\n",
       "\u001b[32mexpensive and slow. This suggests that selecting the most relevant information for knowledge-intensive tasks is \u001b[0m\n",
       "\u001b[32mstill crucial. Retrieval Methods Retrieval-augmented language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRALMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have seen improvements in various \u001b[0m\n",
       "\u001b[32mcomponents: the retriever, the reader, and end-to-end system training. Retrieval methods have transitioned from \u001b[0m\n",
       "\u001b[32mtraditional term-based techniques like TF-IDF \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSp¨arck Jones, 1972\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and BM25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRobertson et al., 1995; Roberts et \u001b[0m\n",
       "\u001b[32mal., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to deep learning–based strategies \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpukhin et al., 2020; Khattab & Zaharia, 2020; Sachan et al., \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Some recent work proposes using large language models as retrievers due to their ability to memorize \u001b[0m\n",
       "\u001b[32mextensive knowledge \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2022; Sun et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Research on the reader component includes \u001b[0m\n",
       "\u001b[32mFusion-in-Decoder \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFiD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mIzacard & Grave, 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which employs both DPR and BM25 for retrieval and processes \u001b[0m\n",
       "\u001b[32mpassages independently in the encoder and RETRO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBorgeaud et al., 2022; Wang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which utilizes \u001b[0m\n",
       "\u001b[32mcross-chunked attention and chunkwise retrieval to generate text grounded on retrieved context. End-to-end system \u001b[0m\n",
       "\u001b[32mtraining work includes Atlas \u001b[0m\u001b[32m(\u001b[0m\u001b[32mIzacard et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which fine-tunes an encoder-decoder model in conjunction with \u001b[0m\n",
       "\u001b[32mthe retriever; REALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGuu et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a bidirectional, masked LM fine-tuned for open-domain question answering; \u001b[0m\n",
       "\u001b[32mand RAG \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRetrieval-Augmented Genera-tion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLewis et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which integrates pre-trained sequence-to-sequence \u001b[0m\n",
       "\u001b[32mmodels with a neural retriever. Min et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m introduced Joint Passage Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJPR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m model which uses a \u001b[0m\n",
       "\u001b[32mtree-decoding algorithm to handle passage diversity and relevance in multi-answer retrieval. Dense Hi-erarchical \u001b[0m\n",
       "\u001b[32mRetrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Hybrid Hierarchical Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m represent advancements in retrieval accuracy by combining \u001b[0m\n",
       "\u001b[32mdocument and passage level retrievals and integrating sparse and dense retrieval methods, respectively \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al.,\u001b[0m\n",
       "\u001b[32m2021; Arivazhagan et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Despite a diversity in methods, the retrieving components of models predominantly \u001b[0m\n",
       "\u001b[32mrely on stan-dard approaches, i.e., chunking corpora and encoding with BERT-based retrievers. Although this \u001b[0m\n",
       "\u001b[32mapproach is widely adopted, Nair et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m highlights a potential shortcoming: contiguous seg-mentation might \u001b[0m\n",
       "\u001b[32mnot capture the complete semantic depth of the text. Reading extracted snippets from technical or scientific \u001b[0m\n",
       "\u001b[32mdocuments may lack important context making them difficult to read or even misleading. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCohan & Goharian, 2017; \u001b[0m\n",
       "\u001b[32mNewman et al., 2023; Zhang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Recursive summarization as Context Summarization techniques provide a \u001b[0m\n",
       "\u001b[32mcondensed view of documents, enabling more focused engagement with the content \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAngelidis & Lapata, 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The \u001b[0m\n",
       "\u001b[32msummarization/snippet model by Gao et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m uses summarizations and snippets of passages, which improves \u001b[0m\n",
       "\u001b[32mcorrectness on most datasets but can sometimes be a lossy means of compression. The recursive-abstractive \u001b[0m\n",
       "\u001b[32msummarization model by Wu et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m employs task decomposition to summarize smaller text chunks, which are \u001b[0m\n",
       "\u001b[32mlater integrated to form summaries of larger sections. While this method is effective for capturing broader themes,\u001b[0m\n",
       "\u001b[32mit can miss granular details. LlamaIndex \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu, 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m mitigates this issue by similarly summarizing adjacent text \u001b[0m\n",
       "\u001b[32mchunks but also retaining intermediate nodes thus storing varying levels of detail, keeping granular details. \u001b[0m\n",
       "\u001b[32mHowever, both methods, due to their reliance on adjacency for grouping or summarizing adjacent nodes, may still \u001b[0m\n",
       "\u001b[32moverlook distant interdependencies within the text, which we can find and group with RAPTOR.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'3 METHODS'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi-cal \u001b[0m\n",
       "\u001b[32mstructures \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCao & Wang, 2022; Dong et al., 2023b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, RAPTOR addresses the issue of semantic depth and connection in \u001b[0m\n",
       "\u001b[32mreading by building a recursive tree structure that balances broader thematic comprehension with granular details \u001b[0m\n",
       "\u001b[32mand which allows nodes to be grouped based on semantic sim-ilarity not just order in the text. Construction of the \u001b[0m\n",
       "\u001b[32mRAPTOR tree begins with segmenting the retrieval corpus into short, contiguous texts of length 100, similar to \u001b[0m\n",
       "\u001b[32mtraditional retrieval augmentation techniques. If a sentence exceeds the 100-token limit, we move the entire \u001b[0m\n",
       "\u001b[32msentence to the next chunk, rather than cutting it mid-sentence. This preserves the contextual and semantic \u001b[0m\n",
       "\u001b[32mcoherence of the text within each chunk. These texts are then embedded using SBERT, a BERT-based encoder \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mmulti-qa-mpnet-base-cos-v1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mReimers & Gurevych, 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The chunks and their corresponding SBERT embeddings form \u001b[0m\n",
       "\u001b[32mthe leaf nodes of our tree structure. To group similar text chunks, we employ a clustering algorithm. Once \u001b[0m\n",
       "\u001b[32mclustered, a Language Model is used to summarize the grouped texts. These summarized texts are then re-embedded, \u001b[0m\n",
       "\u001b[32mand the cycle of embedding, clustering, and summarization continues until further clustering becomes infeasible, \u001b[0m\n",
       "\u001b[32mresulting in a structured, multi-layered tree representation of the original documents. An important aspect of \u001b[0m\n",
       "\u001b[32mRAPTOR is its computational efficiency. The system scales linearly in terms of both build time and token \u001b[0m\n",
       "\u001b[32mexpenditure, making it suitable for processing large and complex corpora. For a comprehensive discussion on \u001b[0m\n",
       "\u001b[32mRAPTOR’s scalability, please refer to the Appendix A. For querying within this tree, we introduce two distinct \u001b[0m\n",
       "\u001b[32mstrategies: tree traversal and collapsed tree. The tree traversal method traverses the tree layer-by-layer, pruning\u001b[0m\n",
       "\u001b[32mand selecting the most relevant nodes at each level. The collapsed tree method evaluates nodes collectively across \u001b[0m\n",
       "\u001b[32mall layers to find the most relevant ones.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'3.1 Clustering Algorithm'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive \u001b[0m\n",
       "\u001b[32mgroups. This step groups related content together, which helps the subsequent retrieval process. One of the unique \u001b[0m\n",
       "\u001b[32maspects of our clustering approach is the use of soft clustering, where nodes can belong to multiple clusters \u001b[0m\n",
       "\u001b[32mwithout requiring a fixed number of clusters. This flexibility is essen-tial because individual text segments often\u001b[0m\n",
       "\u001b[32mcontain information relevant to various topics, thereby warranting their inclusion in multiple summaries. Our \u001b[0m\n",
       "\u001b[32mclustering algorithm is based on Gaussian Mixture Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGMMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, an approach that offers both flexibility and a \u001b[0m\n",
       "\u001b[32mprobabilistic framework. GMMs assume that data points are generated from a mixture of several Gaussian \u001b[0m\n",
       "\u001b[32mdistributions. Given a set of N text segments, each represented as a d-dimensional dense vector embedding, the \u001b[0m\n",
       "\u001b[32mlikelihood of a text vector, x, given its membership in the kth Gaussian distribution, is denoted by P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx|k\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = N\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx; \u001b[0m\n",
       "\u001b[32mµk, Σk\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The overall probability distribution is a weighted combination P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = PK \u001b[0m\u001b[32mk\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m πkN\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx; µk, Σk\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where πk \u001b[0m\n",
       "\u001b[32msignifies the mixture weight for the kth Gaussian distribution. The high dimensionality of vector embeddings \u001b[0m\n",
       "\u001b[32mpresents a challenge for traditional GMMs, as dis-tance metrics may behave poorly when used to measure similarity \u001b[0m\n",
       "\u001b[32min high-dimensional spaces \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAg-garwal et al., 2001\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To mitigate this, we employ Uniform Manifold Approximation and\u001b[0m\n",
       "\u001b[32mProjection \u001b[0m\u001b[32m(\u001b[0m\u001b[32mUMAP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a manifold learning technique for dimensionality reduction \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMcInnes et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The number of\u001b[0m\n",
       "\u001b[32mnearest neighbors parameter, n neighbors, in UMAP determines the balance between the preservation of local and \u001b[0m\n",
       "\u001b[32mglobal structures. Our algorithm varies n neighbors to create a hierar-chical clustering structure: it first \u001b[0m\n",
       "\u001b[32midentifies global clusters and then performs local clustering within these global clusters. This two-step \u001b[0m\n",
       "\u001b[32mclustering process captures a broad spectrum of relationships among the text data, from broad themes to specific \u001b[0m\n",
       "\u001b[32mdetails. Should a local cluster’s combined context ever exceed the summarization model’s token threshold, our \u001b[0m\n",
       "\u001b[32malgorithm recursively applies clustering within the cluster, ensuring that the context remains within the token \u001b[0m\n",
       "\u001b[32mthreshold. To determine the optimal number of clusters, we employ the Bayesian Information Criterion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBIC\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for \u001b[0m\n",
       "\u001b[32mmodel selection. BIC not only penalizes model complexity but also rewards goodness of fit \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchwarz, 1978\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The BIC \u001b[0m\n",
       "\u001b[32mfor a given GMM is BIC = ln\u001b[0m\u001b[32m(\u001b[0m\u001b[32mN\u001b[0m\u001b[32m)\u001b[0m\u001b[32mk −2 ln\u001b[0m\u001b[32m(\u001b[0m\u001b[32mˆL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where N is the number of text segments \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor data points\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, k is the number\u001b[0m\n",
       "\u001b[32mof model parameters, and ˆL is the maximized value of the likelihood function of the model. In the context of GMM, \u001b[0m\n",
       "\u001b[32mthe number of parameters k is a function of the dimensionality of the input vectors and the number of clusters. \u001b[0m\n",
       "\u001b[32mWith the optimal number of clusters determined by BIC, the Expectation-Maximization algorithm is then used to \u001b[0m\n",
       "\u001b[32mestimate the GMM parameters, namely the means, covariances, and mixture weights. While the Gaussian assumption in \u001b[0m\n",
       "\u001b[32mGMMs may not perfectly align with the nature of text data, which often exhibits a sparse and skewed distribution, \u001b[0m\n",
       "\u001b[32mour empirical observations suggest that it offers an effective model for our purpose. We run an ablation comparing \u001b[0m\n",
       "\u001b[32mGMM Clustering with summarizing contiguous chunks and provide details in Appendix B.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'3.2 Model-Based Summarization'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'After clustering the nodes using Gaussian Mixture Models, the nodes in each cluster are sent to a \u001b[0m\n",
       "\u001b[32mlanguage model for summarization. This step allows the model to transform large chunks of text into concise, \u001b[0m\n",
       "\u001b[32mcoherent summaries of the selected nodes. For our experiments, we use gpt-3.5-turbo to generate the summaries. The \u001b[0m\n",
       "\u001b[32msummarization step con-denses the potentially large volume of retrieved information into a manageable size. We \u001b[0m\n",
       "\u001b[32mprovide statistics on the compression due to the summarization in Appendix C and the prompt used for summarization \u001b[0m\n",
       "\u001b[32min Appendix D. While the summarization model generally produces reliable summaries, a focused annotation study \u001b[0m\n",
       "\u001b[32mrevealed that about 4% of the summaries contained minor hallucinations. These did not propagate to parent nodes and\u001b[0m\n",
       "\u001b[32mhad no discernible impact on question-answering tasks. For an in-depth analysis of hallucinations, refer to the \u001b[0m\n",
       "\u001b[32mappendix E.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'4 EXPERIMENTS'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Datasets We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, \u001b[0m\n",
       "\u001b[32mQASPER, and QuALITY. NarrativeQA is a dataset that comprises question-answer pairs based on the full texts of books\u001b[0m\n",
       "\u001b[32mand movie transcripts, totaling 1,572 documents \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKoˇcisk`y et al., 2018; Wu et al., 2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The NarrativeQA-Story \u001b[0m\n",
       "\u001b[32mtask requires a comprehensive understanding of the entire narrative in order to accurately answer its questions, \u001b[0m\n",
       "\u001b[32mthus testing the model’s ability to comprehend longer texts in the literary domain. We measure performance on this \u001b[0m\n",
       "\u001b[32mdataset using the standard BLEU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mB-1, B-4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, ROUGE \u001b[0m\u001b[32m(\u001b[0m\u001b[32mR-L\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and METEOR \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m metrics. Please see appendix H for more \u001b[0m\n",
       "\u001b[32mdetails on the Narra-tiveQA evaluation script used in our experiments. The QASPER dataset includes 5,049 questions \u001b[0m\n",
       "\u001b[32macross 1,585 NLP papers, with each question probing for information embedded within the full text \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDasigi et al., \u001b[0m\n",
       "\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The answer types in QASPER are categorized as Answerable/Unanswerable, Yes/No, Abstractive, and Extractive. \u001b[0m\n",
       "\u001b[32mAccuracy is measured using standard F1. Lastly, the QuALITY dataset consists of multiple-choice questions, each \u001b[0m\n",
       "\u001b[32maccompanied by context passages averaging approximately 5,000 tokens in length \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPang et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This dataset \u001b[0m\n",
       "\u001b[32mcalls for reasoning over the entire document for QA tasks, enabling us to measure the performance of our re-trieval\u001b[0m\n",
       "\u001b[32msystem on medium-length documents. The dataset includes a challenging subset, QuALITY-HARD, which contains \u001b[0m\n",
       "\u001b[32mquestions that a majority of human annotators answered incorrectly in a speed-setting. We report accuracies for \u001b[0m\n",
       "\u001b[32mboth the entire test set and the HARD subset.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mExtractedSectionResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33msection\u001b[0m=\u001b[32m'5 CONCLUSION'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'In this paper, we have presented RAPTOR, a novel tree-based retrieval system that augments the \u001b[0m\n",
       "\u001b[32mparametric knowledge of large language models with contextual information at various levels of abstraction. By \u001b[0m\n",
       "\u001b[32memploying recursive clustering and summarization techniques, RAPTOR creates a hierarchical tree structure that is \u001b[0m\n",
       "\u001b[32mcapable of synthesizing information across various sections of the retrieval corpora. During the query phase, \u001b[0m\n",
       "\u001b[32mRAPTOR leverages this tree structure for more effective retrieval. Our controlled experiments demonstrated that \u001b[0m\n",
       "\u001b[32mRAPTOR not only outperforms traditional retrieval methods but also sets new performance benchmarks on several \u001b[0m\n",
       "\u001b[32mquestion-answering tasks.'\u001b[0m,\n",
       "        \u001b[33mref_fig\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mref_tb\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper = paper_summarizer.get_paper()\n",
    "extracted_section_list = paper_summarizer.extract_section_list(paper.text)\n",
    "print(extracted_section_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ABSTRACT'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Retrieval-augmented language models can better adapt to changes in world state and incorporate </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">limiting holistic understanding of the overall document context. We introduce the novel approach of recursively </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">20% in absolute accuracy.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1 INTRODUCTION'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Large Language Models (LLMs) have emerged as transformative tools showing impressive performance </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on many tasks. With the growing size of LLMs, they can serve standalone as very effective knowledge stores, with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">facts encoded within their parameters (Petroni et al., 2019; Jiang et al., 2020; Talmor et al., 2020; Rae et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021; Hoffmann et al., 2022; Chowdhery et al., 2022; Bubeck et al., 2023; Kandpal et al., 2023) and models can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">further improved with fine-tuning on downstream tasks (Roberts et al., 2020). Nevertheless, even a large model does</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not contain sufficient domain-specific knowledge for particular tasks and the world continues to change, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">invalidating facts in the LLM. Updating the knowledge of these models through additional fine-tuning or editing is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">difficult, particularly when dealing with vast text corpora (Lewis et al., 2020; Mitchell et al., 2022). An </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">alternative approach, pioneered in open domain question answering systems (Chen et al., 2017; Yu et al., 2018), is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to index large quantities of text, after splitting it into chunks (paragraphs), in a separate information retrieval</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system. Retrieved information is then presented to the LLM along with the question as context (“retrieval </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">augmentation”, Lewis et al., 2020; Izacard et al., 2022; Min et al., 2023; Ram et al., 2023), making it easy to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide a system with current knowledge particular to some domain and enabling easy interpretability and provenance</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tracking, whereas the parametric knowledge of LLMs is opaque and difficult to trace back to its source (Akyurek et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2022). Nevertheless, existing retrieval-augmented approaches also have flaws. The one we tackle is that most </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">existing methods retrieve only a few short, contiguous text chunks, which limits their ability to represent and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leverage large-scale discourse structure. This is particularly relevant for thematic questions that require </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">integrating knowledge from multiple parts of a text, such as understanding an entire book, as in the NarrativeQA </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset (Koˇcisk`y et al., 2018). Consider the fairy tale of Cinderella, and the question “How did Cinderella reach</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">her happy ending?”. The top-k retrieved short contiguous texts will not contain enough context to answer the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question. To address this, we design an indexing and retrieval system that uses a tree structure to capture both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">high-level and low-level details about a text. As shown in Figure 1, our system, RAPTOR, clusters chunks of text, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generates text summaries of those clusters, and then repeats, generating a tree from the bottom up. This structure </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enables RAPTOR to load into an LLM’s context chunks representing the text at different levels so that it can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively and efficiently answer questions at different levels.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2 RELATED WORK'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Why Retrieval? Recent advances in hardware and algorithms have indeed expanded the con-text </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">lengths that models can handle, leading to questions about the need for retrieval systems (Dai et al., 2019; Dao et</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2022; Liu et al., 2023). However, as Liu et al. (2023) and Sun et al. (2021) have noted, models tend to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">underutilize long-range context and see diminishing performance as con-text length increases, especially when </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pertinent information is embedded within a lengthy context. Moreover, practically, use of long contexts is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expensive and slow. This suggests that selecting the most relevant information for knowledge-intensive tasks is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">still crucial. Retrieval Methods Retrieval-augmented language models (RALMs) have seen improvements in various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">components: the retriever, the reader, and end-to-end system training. Retrieval methods have transitioned from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional term-based techniques like TF-IDF (Sp¨arck Jones, 1972) and BM25 (Robertson et al., 1995; Roberts et </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">al., 2020) to deep learning–based strategies (Karpukhin et al., 2020; Khattab &amp; Zaharia, 2020; Sachan et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2023). Some recent work proposes using large language models as retrievers due to their ability to memorize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extensive knowledge (Yu et al., 2022; Sun et al., 2022). Research on the reader component includes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Fusion-in-Decoder (FiD) (Izacard &amp; Grave, 2022), which employs both DPR and BM25 for retrieval and processes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">passages independently in the encoder and RETRO (Borgeaud et al., 2022; Wang et al., 2023), which utilizes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cross-chunked attention and chunkwise retrieval to generate text grounded on retrieved context. End-to-end system </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">training work includes Atlas (Izacard et al., 2022), which fine-tunes an encoder-decoder model in conjunction with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the retriever; REALM (Guu et al., 2020), a bidirectional, masked LM fine-tuned for open-domain question answering; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and RAG (Retrieval-Augmented Genera-tion) (Lewis et al., 2020), which integrates pre-trained sequence-to-sequence </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models with a neural retriever. Min et al. (2021) introduced Joint Passage Retrieval (JPR) model which uses a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tree-decoding algorithm to handle passage diversity and relevance in multi-answer retrieval. Dense Hi-erarchical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval (DHR) and Hybrid Hierarchical Retrieval (HHR) represent advancements in retrieval accuracy by combining </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document and passage level retrievals and integrating sparse and dense retrieval methods, respectively (Liu et al.,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021; Arivazhagan et al., 2023). Despite a diversity in methods, the retrieving components of models predominantly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">rely on stan-dard approaches, i.e., chunking corpora and encoding with BERT-based retrievers. Although this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">approach is widely adopted, Nair et al. (2023) highlights a potential shortcoming: contiguous seg-mentation might </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">not capture the complete semantic depth of the text. Reading extracted snippets from technical or scientific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">documents may lack important context making them difficult to read or even misleading. (Cohan &amp; Goharian, 2017; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Newman et al., 2023; Zhang et al., 2023). Recursive summarization as Context Summarization techniques provide a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">condensed view of documents, enabling more focused engagement with the content (Angelidis &amp; Lapata, 2018). The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization/snippet model by Gao et al. (2023) uses summarizations and snippets of passages, which improves </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">correctness on most datasets but can sometimes be a lossy means of compression. The recursive-abstractive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization model by Wu et al. (2021) employs task decomposition to summarize smaller text chunks, which are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">later integrated to form summaries of larger sections. While this method is effective for capturing broader themes,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">it can miss granular details. LlamaIndex (Liu, 2022) mitigates this issue by similarly summarizing adjacent text </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chunks but also retaining intermediate nodes thus storing varying levels of detail, keeping granular details. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">However, both methods, due to their reliance on adjacency for grouping or summarizing adjacent nodes, may still </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">overlook distant interdependencies within the text, which we can find and group with RAPTOR.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3 METHODS'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi-cal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structures (Cao &amp; Wang, 2022; Dong et al., 2023b), RAPTOR addresses the issue of semantic depth and connection in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reading by building a recursive tree structure that balances broader thematic comprehension with granular details </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and which allows nodes to be grouped based on semantic sim-ilarity not just order in the text. Construction of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR tree begins with segmenting the retrieval corpus into short, contiguous texts of length 100, similar to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional retrieval augmentation techniques. If a sentence exceeds the 100-token limit, we move the entire </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">sentence to the next chunk, rather than cutting it mid-sentence. This preserves the contextual and semantic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherence of the text within each chunk. These texts are then embedded using SBERT, a BERT-based encoder </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(multi-qa-mpnet-base-cos-v1) (Reimers &amp; Gurevych, 2019). The chunks and their corresponding SBERT embeddings form </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the leaf nodes of our tree structure. To group similar text chunks, we employ a clustering algorithm. Once </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustered, a Language Model is used to summarize the grouped texts. These summarized texts are then re-embedded, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and the cycle of embedding, clustering, and summarization continues until further clustering becomes infeasible, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">resulting in a structured, multi-layered tree representation of the original documents. An important aspect of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR is its computational efficiency. The system scales linearly in terms of both build time and token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">expenditure, making it suitable for processing large and complex corpora. For a comprehensive discussion on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR’s scalability, please refer to the Appendix A. For querying within this tree, we introduce two distinct </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">strategies: tree traversal and collapsed tree. The tree traversal method traverses the tree layer-by-layer, pruning</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and selecting the most relevant nodes at each level. The collapsed tree method evaluates nodes collectively across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">all layers to find the most relevant ones.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3.1 Clustering Algorithm'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">groups. This step groups related content together, which helps the subsequent retrieval process. One of the unique </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">aspects of our clustering approach is the use of soft clustering, where nodes can belong to multiple clusters </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">without requiring a fixed number of clusters. This flexibility is essen-tial because individual text segments often</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contain information relevant to various topics, thereby warranting their inclusion in multiple summaries. Our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering algorithm is based on Gaussian Mixture Models (GMMs), an approach that offers both flexibility and a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">probabilistic framework. GMMs assume that data points are generated from a mixture of several Gaussian </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">distributions. Given a set of N text segments, each represented as a d-dimensional dense vector embedding, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">likelihood of a text vector, x, given its membership in the kth Gaussian distribution, is denoted by P(x|k) = N(x; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">µk, Σk). The overall probability distribution is a weighted combination P(x) = PK k=1 πkN(x; µk, Σk), where πk </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">signifies the mixture weight for the kth Gaussian distribution. The high dimensionality of vector embeddings </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">presents a challenge for traditional GMMs, as dis-tance metrics may behave poorly when used to measure similarity </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in high-dimensional spaces (Ag-garwal et al., 2001). To mitigate this, we employ Uniform Manifold Approximation and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Projection (UMAP), a manifold learning technique for dimensionality reduction (McInnes et al., 2018). The number of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nearest neighbors parameter, n neighbors, in UMAP determines the balance between the preservation of local and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">global structures. Our algorithm varies n neighbors to create a hierar-chical clustering structure: it first </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">identifies global clusters and then performs local clustering within these global clusters. This two-step </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering process captures a broad spectrum of relationships among the text data, from broad themes to specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details. Should a local cluster’s combined context ever exceed the summarization model’s token threshold, our </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">algorithm recursively applies clustering within the cluster, ensuring that the context remains within the token </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">threshold. To determine the optimal number of clusters, we employ the Bayesian Information Criterion (BIC) for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model selection. BIC not only penalizes model complexity but also rewards goodness of fit (Schwarz, 1978). The BIC </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">for a given GMM is BIC = ln(N)k −2 ln(ˆL), where N is the number of text segments (or data points), k is the number</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of model parameters, and ˆL is the maximized value of the likelihood function of the model. In the context of GMM, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the number of parameters k is a function of the dimensionality of the input vectors and the number of clusters. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">With the optimal number of clusters determined by BIC, the Expectation-Maximization algorithm is then used to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">estimate the GMM parameters, namely the means, covariances, and mixture weights. While the Gaussian assumption in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GMMs may not perfectly align with the nature of text data, which often exhibits a sparse and skewed distribution, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">our empirical observations suggest that it offers an effective model for our purpose. We run an ablation comparing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GMM Clustering with summarizing contiguous chunks and provide details in Appendix B.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'3.2 Model-Based Summarization'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'After clustering the nodes using Gaussian Mixture Models, the nodes in each cluster are sent to a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language model for summarization. This step allows the model to transform large chunks of text into concise, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">coherent summaries of the selected nodes. For our experiments, we use gpt-3.5-turbo to generate the summaries. The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization step con-denses the potentially large volume of retrieved information into a manageable size. We </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide statistics on the compression due to the summarization in Appendix C and the prompt used for summarization </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in Appendix D. While the summarization model generally produces reliable summaries, a focused annotation study </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">revealed that about 4% of the summaries contained minor hallucinations. These did not propagate to parent nodes and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">had no discernible impact on question-answering tasks. For an in-depth analysis of hallucinations, refer to the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appendix E.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'4 EXPERIMENTS'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Datasets We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">QASPER, and QuALITY. NarrativeQA is a dataset that comprises question-answer pairs based on the full texts of books</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and movie transcripts, totaling 1,572 documents (Koˇcisk`y et al., 2018; Wu et al., 2021). The NarrativeQA-Story </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">task requires a comprehensive understanding of the entire narrative in order to accurately answer its questions, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thus testing the model’s ability to comprehend longer texts in the literary domain. We measure performance on this </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset using the standard BLEU (B-1, B-4), ROUGE (R-L), and METEOR (M) metrics. Please see appendix H for more </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details on the Narra-tiveQA evaluation script used in our experiments. The QASPER dataset includes 5,049 questions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across 1,585 NLP papers, with each question probing for information embedded within the full text (Dasigi et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2021). The answer types in QASPER are categorized as Answerable/Unanswerable, Yes/No, Abstractive, and Extractive. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Accuracy is measured using standard F1. Lastly, the QuALITY dataset consists of multiple-choice questions, each </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accompanied by context passages averaging approximately 5,000 tokens in length (Pang et al., 2022). This dataset </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">calls for reasoning over the entire document for QA tasks, enabling us to measure the performance of our re-trieval</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">system on medium-length documents. The dataset includes a challenging subset, QuALITY-HARD, which contains </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions that a majority of human annotators answered incorrectly in a speed-setting. We report accuracies for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">both the entire test set and the HARD subset.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5 CONCLUSION'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'In this paper, we have presented RAPTOR, a novel tree-based retrieval system that augments the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">parametric knowledge of large language models with contextual information at various levels of abstraction. By </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">employing recursive clustering and summarization techniques, RAPTOR creates a hierarchical tree structure that is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">capable of synthesizing information across various sections of the retrieval corpora. During the query phase, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR leverages this tree structure for more effective retrieval. Our controlled experiments demonstrated that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR not only outperforms traditional retrieval methods but also sets new performance benchmarks on several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering tasks.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'ABSTRACT'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Retrieval-augmented language models can better adapt to changes in world state and incorporate \u001b[0m\n",
       "\u001b[32mlong-tail knowledge. However, most existing methods retrieve only short contiguous chunks from a retrieval corpus, \u001b[0m\n",
       "\u001b[32mlimiting holistic understanding of the overall document context. We introduce the novel approach of recursively \u001b[0m\n",
       "\u001b[32membedding, clustering, and summarizing chunks of text, constructing a tree with differing levels of summarization \u001b[0m\n",
       "\u001b[32mfrom the bottom up. At inference time, our RAPTOR model retrieves from this tree, integrating information across \u001b[0m\n",
       "\u001b[32mlengthy documents at different levels of abstraction. Controlled experiments show that retrieval with recursive \u001b[0m\n",
       "\u001b[32msummaries offers significant improvements over traditional retrieval-augmented LMs on several tasks. On \u001b[0m\n",
       "\u001b[32mquestion-answering tasks that involve complex, multi-step reasoning, we show state-of-the-art results; for example,\u001b[0m\n",
       "\u001b[32mby coupling RAPTOR retrieval with the use of GPT-4, we can improve the best performance on the QuALITY benchmark by\u001b[0m\n",
       "\u001b[32m20% in absolute accuracy.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'1 INTRODUCTION'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have emerged as transformative tools showing impressive performance \u001b[0m\n",
       "\u001b[32mon many tasks. With the growing size of LLMs, they can serve standalone as very effective knowledge stores, with \u001b[0m\n",
       "\u001b[32mfacts encoded within their parameters \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPetroni et al., 2019; Jiang et al., 2020; Talmor et al., 2020; Rae et al., \u001b[0m\n",
       "\u001b[32m2021; Hoffmann et al., 2022; Chowdhery et al., 2022; Bubeck et al., 2023; Kandpal et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and models can be \u001b[0m\n",
       "\u001b[32mfurther improved with fine-tuning on downstream tasks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRoberts et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Nevertheless, even a large model does\u001b[0m\n",
       "\u001b[32mnot contain sufficient domain-specific knowledge for particular tasks and the world continues to change, \u001b[0m\n",
       "\u001b[32minvalidating facts in the LLM. Updating the knowledge of these models through additional fine-tuning or editing is \u001b[0m\n",
       "\u001b[32mdifficult, particularly when dealing with vast text corpora \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLewis et al., 2020; Mitchell et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. An \u001b[0m\n",
       "\u001b[32malternative approach, pioneered in open domain question answering systems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mChen et al., 2017; Yu et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, is \u001b[0m\n",
       "\u001b[32mto index large quantities of text, after splitting it into chunks \u001b[0m\u001b[32m(\u001b[0m\u001b[32mparagraphs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, in a separate information retrieval\u001b[0m\n",
       "\u001b[32msystem. Retrieved information is then presented to the LLM along with the question as context \u001b[0m\u001b[32m(\u001b[0m\u001b[32m“retrieval \u001b[0m\n",
       "\u001b[32maugmentation”, Lewis et al., 2020; Izacard et al., 2022; Min et al., 2023; Ram et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, making it easy to \u001b[0m\n",
       "\u001b[32mprovide a system with current knowledge particular to some domain and enabling easy interpretability and provenance\u001b[0m\n",
       "\u001b[32mtracking, whereas the parametric knowledge of LLMs is opaque and difficult to trace back to its source \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAkyurek et \u001b[0m\n",
       "\u001b[32mal., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Nevertheless, existing retrieval-augmented approaches also have flaws. The one we tackle is that most \u001b[0m\n",
       "\u001b[32mexisting methods retrieve only a few short, contiguous text chunks, which limits their ability to represent and \u001b[0m\n",
       "\u001b[32mleverage large-scale discourse structure. This is particularly relevant for thematic questions that require \u001b[0m\n",
       "\u001b[32mintegrating knowledge from multiple parts of a text, such as understanding an entire book, as in the NarrativeQA \u001b[0m\n",
       "\u001b[32mdataset \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKoˇcisk`y et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Consider the fairy tale of Cinderella, and the question “How did Cinderella reach\u001b[0m\n",
       "\u001b[32mher happy ending?”. The top-k retrieved short contiguous texts will not contain enough context to answer the \u001b[0m\n",
       "\u001b[32mquestion. To address this, we design an indexing and retrieval system that uses a tree structure to capture both \u001b[0m\n",
       "\u001b[32mhigh-level and low-level details about a text. As shown in Figure 1, our system, RAPTOR, clusters chunks of text, \u001b[0m\n",
       "\u001b[32mgenerates text summaries of those clusters, and then repeats, generating a tree from the bottom up. This structure \u001b[0m\n",
       "\u001b[32menables RAPTOR to load into an LLM’s context chunks representing the text at different levels so that it can \u001b[0m\n",
       "\u001b[32meffectively and efficiently answer questions at different levels.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'2 RELATED WORK'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Why Retrieval? Recent advances in hardware and algorithms have indeed expanded the con-text \u001b[0m\n",
       "\u001b[32mlengths that models can handle, leading to questions about the need for retrieval systems \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDai et al., 2019; Dao et\u001b[0m\n",
       "\u001b[32mal., 2022; Liu et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. However, as Liu et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Sun et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have noted, models tend to \u001b[0m\n",
       "\u001b[32munderutilize long-range context and see diminishing performance as con-text length increases, especially when \u001b[0m\n",
       "\u001b[32mpertinent information is embedded within a lengthy context. Moreover, practically, use of long contexts is \u001b[0m\n",
       "\u001b[32mexpensive and slow. This suggests that selecting the most relevant information for knowledge-intensive tasks is \u001b[0m\n",
       "\u001b[32mstill crucial. Retrieval Methods Retrieval-augmented language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRALMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have seen improvements in various \u001b[0m\n",
       "\u001b[32mcomponents: the retriever, the reader, and end-to-end system training. Retrieval methods have transitioned from \u001b[0m\n",
       "\u001b[32mtraditional term-based techniques like TF-IDF \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSp¨arck Jones, 1972\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and BM25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRobertson et al., 1995; Roberts et \u001b[0m\n",
       "\u001b[32mal., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to deep learning–based strategies \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpukhin et al., 2020; Khattab & Zaharia, 2020; Sachan et al., \u001b[0m\n",
       "\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Some recent work proposes using large language models as retrievers due to their ability to memorize \u001b[0m\n",
       "\u001b[32mextensive knowledge \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2022; Sun et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Research on the reader component includes \u001b[0m\n",
       "\u001b[32mFusion-in-Decoder \u001b[0m\u001b[32m(\u001b[0m\u001b[32mFiD\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mIzacard & Grave, 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which employs both DPR and BM25 for retrieval and processes \u001b[0m\n",
       "\u001b[32mpassages independently in the encoder and RETRO \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBorgeaud et al., 2022; Wang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which utilizes \u001b[0m\n",
       "\u001b[32mcross-chunked attention and chunkwise retrieval to generate text grounded on retrieved context. End-to-end system \u001b[0m\n",
       "\u001b[32mtraining work includes Atlas \u001b[0m\u001b[32m(\u001b[0m\u001b[32mIzacard et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which fine-tunes an encoder-decoder model in conjunction with \u001b[0m\n",
       "\u001b[32mthe retriever; REALM \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGuu et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a bidirectional, masked LM fine-tuned for open-domain question answering; \u001b[0m\n",
       "\u001b[32mand RAG \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRetrieval-Augmented Genera-tion\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLewis et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which integrates pre-trained sequence-to-sequence \u001b[0m\n",
       "\u001b[32mmodels with a neural retriever. Min et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m introduced Joint Passage Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJPR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m model which uses a \u001b[0m\n",
       "\u001b[32mtree-decoding algorithm to handle passage diversity and relevance in multi-answer retrieval. Dense Hi-erarchical \u001b[0m\n",
       "\u001b[32mRetrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Hybrid Hierarchical Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m represent advancements in retrieval accuracy by combining \u001b[0m\n",
       "\u001b[32mdocument and passage level retrievals and integrating sparse and dense retrieval methods, respectively \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu et al.,\u001b[0m\n",
       "\u001b[32m2021; Arivazhagan et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Despite a diversity in methods, the retrieving components of models predominantly \u001b[0m\n",
       "\u001b[32mrely on stan-dard approaches, i.e., chunking corpora and encoding with BERT-based retrievers. Although this \u001b[0m\n",
       "\u001b[32mapproach is widely adopted, Nair et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m highlights a potential shortcoming: contiguous seg-mentation might \u001b[0m\n",
       "\u001b[32mnot capture the complete semantic depth of the text. Reading extracted snippets from technical or scientific \u001b[0m\n",
       "\u001b[32mdocuments may lack important context making them difficult to read or even misleading. \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCohan & Goharian, 2017; \u001b[0m\n",
       "\u001b[32mNewman et al., 2023; Zhang et al., 2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Recursive summarization as Context Summarization techniques provide a \u001b[0m\n",
       "\u001b[32mcondensed view of documents, enabling more focused engagement with the content \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAngelidis & Lapata, 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The \u001b[0m\n",
       "\u001b[32msummarization/snippet model by Gao et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m uses summarizations and snippets of passages, which improves \u001b[0m\n",
       "\u001b[32mcorrectness on most datasets but can sometimes be a lossy means of compression. The recursive-abstractive \u001b[0m\n",
       "\u001b[32msummarization model by Wu et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m employs task decomposition to summarize smaller text chunks, which are \u001b[0m\n",
       "\u001b[32mlater integrated to form summaries of larger sections. While this method is effective for capturing broader themes,\u001b[0m\n",
       "\u001b[32mit can miss granular details. LlamaIndex \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLiu, 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m mitigates this issue by similarly summarizing adjacent text \u001b[0m\n",
       "\u001b[32mchunks but also retaining intermediate nodes thus storing varying levels of detail, keeping granular details. \u001b[0m\n",
       "\u001b[32mHowever, both methods, due to their reliance on adjacency for grouping or summarizing adjacent nodes, may still \u001b[0m\n",
       "\u001b[32moverlook distant interdependencies within the text, which we can find and group with RAPTOR.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'3 METHODS'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Overview of RAPTOR Building on the idea that long texts often present subtopics and hierarchi-cal \u001b[0m\n",
       "\u001b[32mstructures \u001b[0m\u001b[32m(\u001b[0m\u001b[32mCao & Wang, 2022; Dong et al., 2023b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, RAPTOR addresses the issue of semantic depth and connection in \u001b[0m\n",
       "\u001b[32mreading by building a recursive tree structure that balances broader thematic comprehension with granular details \u001b[0m\n",
       "\u001b[32mand which allows nodes to be grouped based on semantic sim-ilarity not just order in the text. Construction of the \u001b[0m\n",
       "\u001b[32mRAPTOR tree begins with segmenting the retrieval corpus into short, contiguous texts of length 100, similar to \u001b[0m\n",
       "\u001b[32mtraditional retrieval augmentation techniques. If a sentence exceeds the 100-token limit, we move the entire \u001b[0m\n",
       "\u001b[32msentence to the next chunk, rather than cutting it mid-sentence. This preserves the contextual and semantic \u001b[0m\n",
       "\u001b[32mcoherence of the text within each chunk. These texts are then embedded using SBERT, a BERT-based encoder \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mmulti-qa-mpnet-base-cos-v1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mReimers & Gurevych, 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The chunks and their corresponding SBERT embeddings form \u001b[0m\n",
       "\u001b[32mthe leaf nodes of our tree structure. To group similar text chunks, we employ a clustering algorithm. Once \u001b[0m\n",
       "\u001b[32mclustered, a Language Model is used to summarize the grouped texts. These summarized texts are then re-embedded, \u001b[0m\n",
       "\u001b[32mand the cycle of embedding, clustering, and summarization continues until further clustering becomes infeasible, \u001b[0m\n",
       "\u001b[32mresulting in a structured, multi-layered tree representation of the original documents. An important aspect of \u001b[0m\n",
       "\u001b[32mRAPTOR is its computational efficiency. The system scales linearly in terms of both build time and token \u001b[0m\n",
       "\u001b[32mexpenditure, making it suitable for processing large and complex corpora. For a comprehensive discussion on \u001b[0m\n",
       "\u001b[32mRAPTOR’s scalability, please refer to the Appendix A. For querying within this tree, we introduce two distinct \u001b[0m\n",
       "\u001b[32mstrategies: tree traversal and collapsed tree. The tree traversal method traverses the tree layer-by-layer, pruning\u001b[0m\n",
       "\u001b[32mand selecting the most relevant nodes at each level. The collapsed tree method evaluates nodes collectively across \u001b[0m\n",
       "\u001b[32mall layers to find the most relevant ones.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'3.1 Clustering Algorithm'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Clustering plays a key role in building the RAPTOR tree, organizing text segments into cohesive \u001b[0m\n",
       "\u001b[32mgroups. This step groups related content together, which helps the subsequent retrieval process. One of the unique \u001b[0m\n",
       "\u001b[32maspects of our clustering approach is the use of soft clustering, where nodes can belong to multiple clusters \u001b[0m\n",
       "\u001b[32mwithout requiring a fixed number of clusters. This flexibility is essen-tial because individual text segments often\u001b[0m\n",
       "\u001b[32mcontain information relevant to various topics, thereby warranting their inclusion in multiple summaries. Our \u001b[0m\n",
       "\u001b[32mclustering algorithm is based on Gaussian Mixture Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGMMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, an approach that offers both flexibility and a \u001b[0m\n",
       "\u001b[32mprobabilistic framework. GMMs assume that data points are generated from a mixture of several Gaussian \u001b[0m\n",
       "\u001b[32mdistributions. Given a set of N text segments, each represented as a d-dimensional dense vector embedding, the \u001b[0m\n",
       "\u001b[32mlikelihood of a text vector, x, given its membership in the kth Gaussian distribution, is denoted by P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx|k\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = N\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx; \u001b[0m\n",
       "\u001b[32mµk, Σk\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The overall probability distribution is a weighted combination P\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx\u001b[0m\u001b[32m)\u001b[0m\u001b[32m = PK \u001b[0m\u001b[32mk\u001b[0m\u001b[32m=\u001b[0m\u001b[32m1\u001b[0m\u001b[32m πkN\u001b[0m\u001b[32m(\u001b[0m\u001b[32mx; µk, Σk\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where πk \u001b[0m\n",
       "\u001b[32msignifies the mixture weight for the kth Gaussian distribution. The high dimensionality of vector embeddings \u001b[0m\n",
       "\u001b[32mpresents a challenge for traditional GMMs, as dis-tance metrics may behave poorly when used to measure similarity \u001b[0m\n",
       "\u001b[32min high-dimensional spaces \u001b[0m\u001b[32m(\u001b[0m\u001b[32mAg-garwal et al., 2001\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. To mitigate this, we employ Uniform Manifold Approximation and\u001b[0m\n",
       "\u001b[32mProjection \u001b[0m\u001b[32m(\u001b[0m\u001b[32mUMAP\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, a manifold learning technique for dimensionality reduction \u001b[0m\u001b[32m(\u001b[0m\u001b[32mMcInnes et al., 2018\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The number of\u001b[0m\n",
       "\u001b[32mnearest neighbors parameter, n neighbors, in UMAP determines the balance between the preservation of local and \u001b[0m\n",
       "\u001b[32mglobal structures. Our algorithm varies n neighbors to create a hierar-chical clustering structure: it first \u001b[0m\n",
       "\u001b[32midentifies global clusters and then performs local clustering within these global clusters. This two-step \u001b[0m\n",
       "\u001b[32mclustering process captures a broad spectrum of relationships among the text data, from broad themes to specific \u001b[0m\n",
       "\u001b[32mdetails. Should a local cluster’s combined context ever exceed the summarization model’s token threshold, our \u001b[0m\n",
       "\u001b[32malgorithm recursively applies clustering within the cluster, ensuring that the context remains within the token \u001b[0m\n",
       "\u001b[32mthreshold. To determine the optimal number of clusters, we employ the Bayesian Information Criterion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBIC\u001b[0m\u001b[32m)\u001b[0m\u001b[32m for \u001b[0m\n",
       "\u001b[32mmodel selection. BIC not only penalizes model complexity but also rewards goodness of fit \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSchwarz, 1978\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The BIC \u001b[0m\n",
       "\u001b[32mfor a given GMM is BIC = ln\u001b[0m\u001b[32m(\u001b[0m\u001b[32mN\u001b[0m\u001b[32m)\u001b[0m\u001b[32mk −2 ln\u001b[0m\u001b[32m(\u001b[0m\u001b[32mˆL\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, where N is the number of text segments \u001b[0m\u001b[32m(\u001b[0m\u001b[32mor data points\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, k is the number\u001b[0m\n",
       "\u001b[32mof model parameters, and ˆL is the maximized value of the likelihood function of the model. In the context of GMM, \u001b[0m\n",
       "\u001b[32mthe number of parameters k is a function of the dimensionality of the input vectors and the number of clusters. \u001b[0m\n",
       "\u001b[32mWith the optimal number of clusters determined by BIC, the Expectation-Maximization algorithm is then used to \u001b[0m\n",
       "\u001b[32mestimate the GMM parameters, namely the means, covariances, and mixture weights. While the Gaussian assumption in \u001b[0m\n",
       "\u001b[32mGMMs may not perfectly align with the nature of text data, which often exhibits a sparse and skewed distribution, \u001b[0m\n",
       "\u001b[32mour empirical observations suggest that it offers an effective model for our purpose. We run an ablation comparing \u001b[0m\n",
       "\u001b[32mGMM Clustering with summarizing contiguous chunks and provide details in Appendix B.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'3.2 Model-Based Summarization'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'After clustering the nodes using Gaussian Mixture Models, the nodes in each cluster are sent to a \u001b[0m\n",
       "\u001b[32mlanguage model for summarization. This step allows the model to transform large chunks of text into concise, \u001b[0m\n",
       "\u001b[32mcoherent summaries of the selected nodes. For our experiments, we use gpt-3.5-turbo to generate the summaries. The \u001b[0m\n",
       "\u001b[32msummarization step con-denses the potentially large volume of retrieved information into a manageable size. We \u001b[0m\n",
       "\u001b[32mprovide statistics on the compression due to the summarization in Appendix C and the prompt used for summarization \u001b[0m\n",
       "\u001b[32min Appendix D. While the summarization model generally produces reliable summaries, a focused annotation study \u001b[0m\n",
       "\u001b[32mrevealed that about 4% of the summaries contained minor hallucinations. These did not propagate to parent nodes and\u001b[0m\n",
       "\u001b[32mhad no discernible impact on question-answering tasks. For an in-depth analysis of hallucinations, refer to the \u001b[0m\n",
       "\u001b[32mappendix E.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'4 EXPERIMENTS'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'Datasets We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, \u001b[0m\n",
       "\u001b[32mQASPER, and QuALITY. NarrativeQA is a dataset that comprises question-answer pairs based on the full texts of books\u001b[0m\n",
       "\u001b[32mand movie transcripts, totaling 1,572 documents \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKoˇcisk`y et al., 2018; Wu et al., 2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The NarrativeQA-Story \u001b[0m\n",
       "\u001b[32mtask requires a comprehensive understanding of the entire narrative in order to accurately answer its questions, \u001b[0m\n",
       "\u001b[32mthus testing the model’s ability to comprehend longer texts in the literary domain. We measure performance on this \u001b[0m\n",
       "\u001b[32mdataset using the standard BLEU \u001b[0m\u001b[32m(\u001b[0m\u001b[32mB-1, B-4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, ROUGE \u001b[0m\u001b[32m(\u001b[0m\u001b[32mR-L\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and METEOR \u001b[0m\u001b[32m(\u001b[0m\u001b[32mM\u001b[0m\u001b[32m)\u001b[0m\u001b[32m metrics. Please see appendix H for more \u001b[0m\n",
       "\u001b[32mdetails on the Narra-tiveQA evaluation script used in our experiments. The QASPER dataset includes 5,049 questions \u001b[0m\n",
       "\u001b[32macross 1,585 NLP papers, with each question probing for information embedded within the full text \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDasigi et al., \u001b[0m\n",
       "\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. The answer types in QASPER are categorized as Answerable/Unanswerable, Yes/No, Abstractive, and Extractive. \u001b[0m\n",
       "\u001b[32mAccuracy is measured using standard F1. Lastly, the QuALITY dataset consists of multiple-choice questions, each \u001b[0m\n",
       "\u001b[32maccompanied by context passages averaging approximately 5,000 tokens in length \u001b[0m\u001b[32m(\u001b[0m\u001b[32mPang et al., 2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. This dataset \u001b[0m\n",
       "\u001b[32mcalls for reasoning over the entire document for QA tasks, enabling us to measure the performance of our re-trieval\u001b[0m\n",
       "\u001b[32msystem on medium-length documents. The dataset includes a challenging subset, QuALITY-HARD, which contains \u001b[0m\n",
       "\u001b[32mquestions that a majority of human annotators answered incorrectly in a speed-setting. We report accuracies for \u001b[0m\n",
       "\u001b[32mboth the entire test set and the HARD subset.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mSectionInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'5 CONCLUSION'\u001b[0m,\n",
       "        \u001b[33mcontent\u001b[0m=\u001b[32m'In this paper, we have presented RAPTOR, a novel tree-based retrieval system that augments the \u001b[0m\n",
       "\u001b[32mparametric knowledge of large language models with contextual information at various levels of abstraction. By \u001b[0m\n",
       "\u001b[32memploying recursive clustering and summarization techniques, RAPTOR creates a hierarchical tree structure that is \u001b[0m\n",
       "\u001b[32mcapable of synthesizing information across various sections of the retrieval corpora. During the query phase, \u001b[0m\n",
       "\u001b[32mRAPTOR leverages this tree structure for more effective retrieval. Our controlled experiments demonstrated that \u001b[0m\n",
       "\u001b[32mRAPTOR not only outperforms traditional retrieval methods but also sets new performance benchmarks on several \u001b[0m\n",
       "\u001b[32mquestion-answering tasks.'\u001b[0m,\n",
       "        \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "section_info_list = paper_summarizer.get_section_info_list(extracted_section_list)\n",
    "print(section_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SummaryResult</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">keynote</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"### Problem\\n- **What problem does this paper aim to solve?**\\n  The paper addresses the limitations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of current retrieval-augmented language models (LLMs), which typically retrieve only short, contiguous chunks of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text. This limitation hampers the models' ability to understand and leverage the larger context and discourse </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure of documents, particularly in complex, multi-step reasoning tasks.\\n- **What are the existing methods, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and what limitations do they have?**\\n  Existing methods include splitting text into chunks and indexing them for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval, which is then presented to the LLM along with the query. These methods often use BM25, DPR, or other </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">BERT-based retrievers. Their major limitations are:\\n  - Inadequate in representing large-scale discourse.\\n  - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval is limited to shorter, contiguous passages, which fails to capture the holistic context needed for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">answering complex questions.\\n\\n### Solution\\n- **What solution does the paper propose?**\\n  The paper introduces </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR, a recursive abstractive processing method for tree-organized retrieval. This involves recursively </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embedding, clustering, and summarizing text chunks to build a hierarchical tree that provides both high-level and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">detailed summaries. The model retrieves from this tree to incorporate varying levels of abstraction during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference.\\n- **What inspired this idea? Was it influenced by other papers?**\\n  The idea was influenced by recent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">advances in hardware and algorithms that have expanded context handling capabilities and the effectiveness of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hierarchical structures for capturing document semantics.\\n- **What theoretical basis supports this method?**\\n  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The method is theoretically supported by the concept of hierarchical data structures and embedding algorithms that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">allow effective clustering and retrieval. Techniques such as UMAP for dimensionality reduction and Gaussian Mixture</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Models for clustering underpin the theoretical foundation.\\n\\n### Experiment\\n- **How well does the experiment </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">perform?**\\n  The experiments demonstrated that RAPTOR significantly outperforms traditional retrieval-augmented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LMs on several tasks. Notably:\\n  - Achieves state-of-the-art results on question-answering tasks requiring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">complex, multi-step reasoning.\\n  - Improved performance on benchmarks like QuALITY, NarrativeQA, and QASPER.\\n- </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**What limitations or assumptions are associated with this method?**\\n  - Slight hallucinations in model-generated </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summaries (~4% found in an annotation study), though these do not propagate significantly and have minimal impact </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on task performance.\\n  - Requires efficient implementation to handle high computational demands, particularly with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large texts and recursive summarization.\\n\\n### Innovation\\n- **What important or novel discoveries does this paper</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">make?**\\n  - Introduces the concept of a hierarchical tree structure for text retrieval, capturing both high-level </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summaries and detailed information.\\n  - Demonstrates the efficacy of combining summarization and hierarchical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering in improving model performance in long-context, multi-step reasoning tasks.\\n  - Sets new </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">state-of-the-art performance benchmarks on multiple datasets and demonstrates significant improvements over </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">traditional methods.\\n\\n### Comments / Critique\\n- **Are there any limitations in this paper?**\\n  - While RAPTOR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performs well, the recursive summarization process can introduce minor hallucinations.\\n  - The method can be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computationally intensive, requiring efficient scaling strategies.\\n- **Does the paper substantiate its claims </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectively?**\\n  Yes, through controlled experiments and benchmarking against existing state-of-the-art methods. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The paper provides comprehensive evaluation results, showing consistent and statistically significant improvements </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across multiple datasets. Detailed ablation studies and qualitative analyses further support its claims.\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">section_notes</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'ABSTRACT'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'- The abstract discusses a novel methodology for enhancing retrieval-augmented </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language models (LMs).\\n- The methodology helps LMs adapt better to changes in world knowledge and handle nuanced </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information.\\n- Traditional methods that retrieve short, consecutive text segments from a corpus often neglect the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">broader document context.\\n- The presented approach involves recursively embedding, clustering, and summarizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text chunks to create a hierarchical tree structure of summaries.\\n- The RAPTOR model leverages this tree during </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">inference for better integration of document-level information at various abstraction levels.\\n- Experiments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">demonstrate that recursive summaries significantly boost performance compared to traditional models across several </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n- Specifically, RAPTOR achieves state-of-the-art results in complex, multi-step question-answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n- RTPOR improves absolute accuracy on the QuALITY benchmark by 20% when paired with GPT-4.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'NO_QUOTES'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'INTRODUCTION'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"- Large Language Models (LLMs) have shown impressive performance and can store </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge within their parameters, but updating them with new information is challenging.\\n- An alternative method </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">is retrieval augmentation, which retrieves and presents relevant text chunks alongside questions to provide </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">context.\\n- However, existing methods often fail to capture large-scale discourse structures needed for complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">thematic questions.\\n- To address this, the paper introduces RAPTOR, a system that uses a hierarchical tree </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure to capture both high-level and low-level details of a text.\\n- RAPTOR clusters text chunks, generates </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summaries, and builds a tree to improve the LLM's ability to answer multi-level questions accurately and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiently.\\n- The image describes the RAPTOR system, which enhances the performance of Large Language Models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(LLMs) by integrating a hierarchical structure to better manage and retrieve relevant information for complex </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">queries.\\n- Key insights and findings:\\n  - Limitations of Existing Methods: Traditional retrieval augmentation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">methods struggle with large-scale discourse structures, making it difficult for LLMs to handle intricate thematic </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">questions effectively.\\n  - RAPTOR's Structure: RAPTOR utilizes a hierarchical tree model that captures both </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">high-level and low-level details of text. This structure allows for organized representation and retrieval of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information.\\n  - Process Overview:\\n    - Clustering: Text is grouped into chunks, facilitating better </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">organization.\\n    - Summarization by LLM: Each cluster is summarized, allowing for concise representation of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information.\\n    - Tree Formation: These summaries create layers within the tree, with a root layer at the top and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">leaf layers at the bottom, enhancing clarity and retrieval accuracy.\\n  - Node Content: Each node in the RAPTOR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tree contains:\\n    - An index for identification.\\n    - References to its child nodes.\\n    - A summary of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">text from child nodes.\\n    - Text embeddings that represent the content, making it easier to compare and retrieve </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">relevant information.\\n  - Enhanced Answering Capability: By structuring information hierarchically, RAPTOR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improves the LLM’s ability to answer complex, multi-level questions, ultimately leading to more accurate and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contextually rich responses.\\n- In summary, RAPTOR presents a novel framework for integrating hierarchical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">organization in LLMs, addressing existing shortcomings in retrieval processes for complex queries through </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structured clustering and summarization.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&gt; \"With the growing size of LLMs, they can serve standalone as very effective knowledge stores,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with facts encoded within their parameters... models can be further improved with fine-tuning on downstream </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\"\\n\\n**Explanation**: This quote highlights the primary question addressed in the paper, which is the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">impressive performance and capabilities of Large Language Models (LLMs) as knowledge repositories and their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhancement through fine-tuning.\\n\\n&gt; \"Nevertheless, even a large model does not contain sufficient domain-specific</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge for particular tasks and the world continues to change, invalidating facts in the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LLM.\"\\n\\n**Explanation**: This quote emphasizes a major problem the paper addresses: the limitations of LLMs in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handling evolving and domain-specific knowledge, which necessitates frequent updates that are challenging to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">implement.\\n\\n&gt; \"To address this, we design an indexing and retrieval system that uses a tree structure to capture </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">both high-level and low-level details about a text... This structure enables RAPTOR to load into an LLM’s context </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">chunks representing the text at different levels so that it can effectively and efficiently answer questions at </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different levels.\"\\n\\n**Explanation**: This quote describes the proposed solution, RAPTOR, which is an innovative </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">indexing and retrieval system using a tree structure that allows for effective multi-level information retrieval, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">addressing the limitation of current retrieval-augmented methods in handling large-scale discourse structure.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'</span><span style=\"font-weight: bold\">]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'RELATED WORK'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"- The section discusses the importance of retrieval systems despite advancements in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handling long contexts by current models.\\n- It highlights that models underperform with long contexts due to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">underutilization and high costs.\\n- Retrieval-augmented language models (RALMs) have improved in components such as</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the retriever, reader, and end-to-end training.\\n- RALM methods have evolved from traditional techniques like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">TF-IDF and BM25 to deep learning-based strategies.\\n- Techniques like FiD and RETRO are notable approaches </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">providing robust retrieval mechanisms.\\n- End-to-end systems like Atlas, REALM, and RAG offer advancements in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">efficiency.\\n- The section also covers new retrieval models like Joint Passage Retrieval (JPR), Dense Hierarchical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Retrieval (DHR), and Hybrid Hierarchical Retrieval (HHR), which improve accuracy.\\n- Issues like the limitations of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">standard chunking approaches and the potential of recursive summarization techniques are also discussed.\\n- Models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">such as Gao et al.'s superficial summaries and Wu et al.’s recursive-abstractive summarization, along with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LlamaIndex, are explored for addressing these limitations by providing varying levels of detail without losing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">critical interdependencies in the text.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&gt; \"However, as Liu et al. (2023) and Sun et al. (2021) have noted, models tend to underutilize </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">long-range context and see diminishing performance as context length increases, especially when pertinent </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information is embedded within a lengthy context.\"\\n\\n**Explanation**: This quote highlights a critical problem in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">current deep learning models—their inefficiency in utilizing long-range context. It underscores the necessity for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval systems to handle knowledge-intensive tasks effectively.\\n\\n&gt; \"Some recent work proposes using large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language models as retrievers due to their ability to memorize extensive knowledge (Yu et al., 2022; Sun et al., </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">2022).\"\\n\\n**Explanation**: This quote reveals a significant shift in retrieval methods, suggesting the use of </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large language models as retrievers. This represents an innovative approach leveraging the models\\' extensive </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">knowledge memorization capacities.\\n\\n&gt; \"Despite a diversity in methods, the retrieving components of models </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">predominantly rely on standard approaches, i.e., chunking corpora and encoding with BERT-based retrievers... </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">contiguous segmentation might not capture the complete semantic depth of the text.\"\\n\\n**Explanation**: This quote </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">points out potential shortcomings in current retrieval techniques, emphasizing the limitations of standard chunking</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and encoding methods. This critical insight challenges the community to develop more nuanced and context-aware </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">retrieval systems.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'METHODS'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"- The section describes the methods used in the RAPTOR system, which is designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handle long texts with multiple subtopics by organizing information into a recursive tree structure.\\n- This is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">achieved through several steps:\\n    - **Text Segmentation**: The text is divided into contiguous chunks, ensuring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">semantic coherence by not splitting sentences.\\n    - **Embedding**: Each chunk is embedded using SBERT, forming </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the leaf nodes of the tree.\\n    - **Clustering**: Text chunks with similar content are grouped using a soft </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">clustering algorithm based on Gaussian Mixture Models (GMMs).\\n    - **Summarization**: The clusters are summarized</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using a language model, such as gpt-3.5-turbo. This process of embedding, clustering, and summarizing repeats </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recursively until further clustering is no longer feasible, forming a multi-layered tree.\\n- The RAPTOR system is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">computationally efficient, scaling linearly with respect to build time and token usage, making it suitable for </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">large and complex corpora.\\n- Two query strategies—tree traversal and collapsed tree—are introduced to navigate the</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hierarchical structure.\\n- For clustering, the method utilizes GMMs, providing flexibility by allowing nodes to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">belong to multiple clusters.\\n- UMAP is used for dimensionality reduction to improve clustering in high-dimensional</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">spaces.\\n- The optimal number of clusters is determined using the Bayesian Information Criterion (BIC).\\n- In the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization phase, gpt-3.5-turbo generates concise summaries of the clustered text.\\n- Despite occasional minor </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">hallucinations in the summaries, they do not significantly impact overall performance in question-answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n- Further details about scalability, comparison with other methods, summarization compression, and handling</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">of hallucinations are available in the paper's appendices.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&gt; \"RAPTOR addresses the issue of semantic depth and connection in reading by building a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">recursive tree structure that balances broader thematic comprehension with granular details and which allows nodes </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">to be grouped based on semantic similarity not just order in the text.\"\\n\\n**Explanation**: This quote is important</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">as it highlights the primary problem RAPTOR aims to solve: enhancing semantic depth and connectivity in long texts </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">by utilizing a recursive tree structure. This structure aids in understanding both broad themes and specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">details.\\n\\n&gt; \"One of the unique aspects of our clustering approach is the use of soft clustering, where nodes can </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">belong to multiple clusters without requiring a fixed number of clusters. This flexibility is essential because </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">individual text segments often contain information relevant to various topics, thereby warranting their inclusion </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">in multiple summaries.\"\\n\\n**Explanation**: This quote is important because it describes a key feature of RAPTOR\\'s</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">method—soft clustering via Gaussian Mixture Models. This method provides flexibility by allowing text segments to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">belong to multiple clusters, addressing the complexity of information that often overlaps different topics.\\n\\n&gt; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"An important aspect of RAPTOR is its computational efficiency. The system scales linearly in terms of both build </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">time and token expenditure, making it suitable for processing large and complex corpora.\"\\n\\n**Explanation**: This </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quote underscores the practical significance of RAPTOR by pointing out its computational efficiency. The linear </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scalability in terms of computational resources means that RAPTOR is well-suited for handling extensive and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">intricate corpora, which is critical for real-world applications.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'EXPERIMENTS'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'- The section titled \"EXPERIMENTS\" details the evaluation of RAPTOR\\'s performance on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">three distinct question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n- **NarrativeQA** involves questions</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">derived from books and movie transcripts and assesses the model’s comprehension of longer texts. Performance is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">measured using BLEU, ROUGE, and METEOR metrics.\\n- **QASPER** consists of questions about NLP papers, challenging </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the model\\'s ability to extract and synthesize information. The dataset includes four types of answers and is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluated using F1 accuracy.\\n- **QuALITY** includes multiple-choice questions with context passages, measuring </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning over medium-length documents, and includes a particularly difficult subset called QuALITY-HARD.\\n- The </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">section also presents controlled baseline comparisons using UnifiedQA 3B reader and various embedding models with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and without RAPTOR\\'s tree structure.\\n- Results indicate that RAPTOR enhances performance across all datasets and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">embedding models when compared to SBERT, BM25, and DPR alone.\\n- Further comparisons using GPT-3, GPT-4, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">UnifiedQA on the QASPER dataset demonstrate that RAPTOR consistently outperforms these benchmarks, leveraging </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">higher-level summary nodes for superior information synthesis.\\n- The \"EXPERIMENTS\" section assesses RAPTOR’s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectiveness across three specific question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Datasets </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Overview**:\\n    - **NarrativeQA**: Focuses on comprehension of longer texts, evaluating models primarily using </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">BLEU, ROUGE, and METEOR metrics.\\n    - **QASPER**: Tests the ability to extract and synthesize information from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">NLP papers, with evaluation based on F1 accuracy and various answer types.\\n    - **QuALITY**: Features </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">multiple-choice questions related to context passages, particularly assessing reasoning capabilities, including a </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenging subset called QuALITY-HARD.\\n  - **Performance Metrics**:\\n    - The metrics used for evaluation </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">include ROUGE, BLEU (1 and 4), and METEOR, which measure different aspects of generated text relevance and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quality.\\n  - **Controlled Comparisons**:\\n    - The experiments include evaluations against various baseline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models: SBERT, BM25, and DPR, both with and without RAPTOR’s tree structure.\\n    - RAPTOR consistently enhances </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">performance across all models and datasets.\\n  - **Key Findings**:\\n    - Models incorporating RAPTOR (SBERT with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR, BM25 with RAPTOR, and DPR with RAPTOR) outperform their counterparts without it.\\n    - For example, SBERT </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with RAPTOR achieves a ROUGE score of 30.87% compared to 29.26% without it, demonstrating RAPTOR\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">effectiveness.\\n    - The enhancements are evident in all metrics, with RAPTOR facilitating improved information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">synthesis and understanding.\\n  - **Comparison with Advanced Models**:\\n    - When compared to advanced models like</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">GPT-3 and GPT-4 on the QASPER dataset, RAPTOR shows superior performance, leveraging the structure of higher-level </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summary nodes for better outcomes.\\n  - Overall, RAPTOR significantly boosts performance in question-answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks, demonstrating its utility and effectiveness in enhancing comprehension and synthesis of information across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">varied datasets.\\n- The section titled \"EXPERIMENTS\" evaluates the performance of the RAPTOR model across three </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Datasets Overview**:\\n    - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**NarrativeQA**: Focuses on understanding longer narratives, derived from books and movies. Performance is assessed</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">using BLEU, ROUGE, and METEOR metrics.\\n    - **QASPER**: Comprises questions related to NLP papers, emphasizing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the model\\'s ability to extract and synthesize information. Evaluated using F1 accuracy across four answer types.\\n</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">- **QuALITY**: Involves multiple-choice questions based on context passages, measuring reasoning capabilities. A </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">challenging subset, QuALITY-HARD, is also included.\\n  - **Performance Comparison**:\\n    - RAPTOR\\'s integration </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">consistently improves performance when combined with other models (e.g., SBERT, BM25, DPR) compared to their </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">standalone performances.\\n    - For example, SBERT with RAPTOR achieved an accuracy of 56.6% in the QuALITY </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">dataset, while SBERT without RAPTOR had a slightly lower accuracy of 54.9%.\\n    - Similar enhancements are noted </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">across all models tested, indicating that RAPTOR effectively enhances model capabilities.\\n  - **Benchmarking </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Against Existing Models**:\\n    - Further evaluations using state-of-the-art models like GPT-3, GPT-4, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">UnifiedQA demonstrate that RAPTOR outperforms these benchmarks on the QASPER dataset.\\n    - The model appears to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">excel in synthesizing information by leveraging higher-level summary nodes, contributing to improved answer </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extraction and synthesis.\\n  - **Quantitative Results**:\\n    - The tabulated results show RAPTOR\\'s combination </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">with SBERT, BM25, and DPR results in higher metrics for both QuALITY and QASPER datasets, highlighting RAPTOR\\'s </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">beneficial impact on model performance.\\n    - The F1 scores for QASPER also reveal that RAPTOR-led combinations </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">yield better performance, emphasizing its ability to enhance answer extraction capabilities.\\n  - Overall, the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">experiments illustrate RAPTOR\\'s efficacy in improving the performance of existing models across various </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">question-answering tasks, showcasing its potential as a valuable component in natural language processing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">applications.\\n- The section titled \"EXPERIMENTS\" provides a comprehensive evaluation of the RAPTOR model across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">three distinct question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Dataset Evaluations**:\\n    - </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">**NarrativeQA**: Assesses comprehension of lengthy texts through questions related to books and movie transcripts. </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Performance is evaluated using metrics like BLEU, ROUGE, and METEOR.\\n    - **QASPER**: Focuses on questions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">derived from NLP papers, testing the model\\'s ability to extract and synthesize information from these sources. It </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">uses F1 accuracy for its evaluations.\\n    - **QuALITY**: Involves multiple-choice questions with context passages,</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">emphasizing reasoning over medium-length documents. A particularly challenging subset, QuALITY-HARD, is also </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">included to assess performance under difficult conditions.\\n  - **Baseline Comparisons**:\\n    - The experiments </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">provide controlled comparisons against various existing models, including UnifiedQA 3B and different embedding </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">models, contrasting their performance with and without RAPTOR\\'s tree structure.\\n    - RAPTOR consistently </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhances performance across all evaluated datasets and embedding models, outperforming established methods like </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">SBERT, BM25, and DPR.\\n  - **Benchmark Performances**:\\n    - On the QASPER dataset, RAPTOR outperformed large </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language models, including GPT-3 and GPT-4, as well as the UnifiedQA model.\\n    - The F1 scores demonstrate that </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR achieves superior results, largely due to its utilization of higher-level summary nodes which enhance its </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ability to synthesize information effectively.\\n  - **Performance Metrics**:\\n    - Notably, RAPTOR achieves F1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">scores of 53.1 with GPT-3, 55.7 with GPT-4, and 36.6 with UnifiedQA, indicating its strong competency in handling </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the tasks presented across different datasets.\\n  - Overall, these findings highlight RAPTOR\\'s effectiveness in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">improving question-answering capabilities through its advanced structural approach and outperforming multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">established models.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'&gt; \"We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">QASPER, and QuALITY.\"\\n\\n**Explanation**: This quote is important because it identifies the datasets used to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluate the performance of RAPTOR, establishing the context for the experiments.\\n\\n&gt; \"Controlled Baseline </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Comparisons We first present controlled comparisons using the UnifiedQA 3B as the reader, with SBERT (Reimers &amp; </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Gurevych, 2019), BM25 (Robertson et al., 1995; 2009), and DPR (Karpukhin et al., 2020) as the embedding models with</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and without the RAPTOR tree structure, on three datasets: QASPER, NarrativeQA, and QuALITY.\"\\n\\n**Explanation**: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This quote explains the methodology of the controlled baseline comparisons, detailing the embedding models and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">datasets used. It highlights the experimental setup to verify RAPTOR’s performance.\\n\\n&gt; \"As shown in Table 3, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">RAPTOR consistently outperforms BM25 and DPR across all three Language Models on the QASPER dataset. RAPTOR’s F-1 </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Match scores are 53.1%, 55.7%, and 36.6% when using GPT-3, GPT-4, and UnifiedQA, respectively.\"\\n\\n**Explanation**:</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">This quote is crucial as it emphasizes RAPTOR\\'s superior performance over existing methods (BM25 and DPR) across </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">different language models, showcasing significant improvements in F-1 Match scores on the QASPER dataset.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-7-1.jpg'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-8-2.jpg'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-8-3.jpg'</span>\n",
       "            <span style=\"font-weight: bold\">]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'CONCLUSION'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'- The paper introduces RAPTOR, an innovative tree-based retrieval system designed to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">enhance the retrieval capabilities of large language models by incorporating contextual information at multiple </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">abstraction levels.\\n- RAPTOR utilizes recursive clustering and summarization to build a hierarchical tree </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structure, effectively synthesizing information from different parts of the retrieval corpus.\\n- In the query </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">phase, this structure aids in more efficient information retrieval.\\n- Experimental results indicate that RAPTOR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">surpasses traditional retrieval methods and achieves new performance standards in multiple question-answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'NO_QUOTES'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">SectionNote</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">header</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'HALLUCINATION ANALYSIS'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">summary_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"- The section investigates the presence and impact of hallucinations in summaries </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">generated by the RAPTOR model using gpt-3.5-turbo.\\n- Hallucinations refer to inaccuracies wherein the model adds </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">information not present in the source text.\\n- Researchers randomly sampled 150 nodes from 40 stories and manually </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">evaluated them.\\n- They found a 4% hallucination rate, typically involving minor additions or incorrect </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extrapolations that did not significantly alter the text's thematic interpretation.\\n- These hallucinations did not</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">propagate to higher summary layers.\\n- Hallucinations did not impact the performance in question-answering </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks.\\n- Hallucinations are not a critical issue for the RAPTOR model's summarization capabilities.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">quotes</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"&gt; 'To assess the quality and accuracy of the summarizations within our RAPTOR model, we </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">conducted an analysis focusing on hallucinations in the generated summaries.'\\n\\n**Explanation**: This quote is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">important as it outlines the primary objective of this section, which is to evaluate the accuracy of the RAPTOR </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">model's summarizations by examining hallucinations.\\n\\n&gt; 'Out of the 150 nodes sampled, 4% (6 nodes) contained some</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">form of hallucination. Most commonly, these hallucinations originated from the model adding minor information </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">possibly from its training data that was not present in the text being summarized, or from incorrectly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">extrapolating some information when creating the summary.'\\n\\n**Explanation**: This quote highlights the key </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">findings regarding the prevalence and nature of hallucinations in the model's summaries. It gives specific </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">statistics and describes the common causes of the inaccuracies.\\n\\n&gt; 'In our findings, hallucinations had no </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">discernible impact on the performance of QA tasks. This suggests that hallucination is not a major concern for the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">summarization component in our RAPTOR architecture.'\\n\\n**Explanation**: This quote emphasizes a crucial outcome of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the analysis, indicating that despite the presence of some hallucinations, their impact on the overall QA tasks is </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">negligible. This insight is significant for understanding the practical implications of the model's performance.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">image_paths</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">table_paths</span>=<span style=\"font-weight: bold\">[]</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mSummaryResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mkeynote\u001b[0m=\u001b[32m\"### Problem\\n- **What problem does this paper aim to solve?**\\n  The paper addresses the limitations \u001b[0m\n",
       "\u001b[32mof current retrieval-augmented language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which typically retrieve only short, contiguous chunks of \u001b[0m\n",
       "\u001b[32mtext. This limitation hampers the models' ability to understand and leverage the larger context and discourse \u001b[0m\n",
       "\u001b[32mstructure of documents, particularly in complex, multi-step reasoning tasks.\\n- **What are the existing methods, \u001b[0m\n",
       "\u001b[32mand what limitations do they have?**\\n  Existing methods include splitting text into chunks and indexing them for \u001b[0m\n",
       "\u001b[32mretrieval, which is then presented to the LLM along with the query. These methods often use BM25, DPR, or other \u001b[0m\n",
       "\u001b[32mBERT-based retrievers. Their major limitations are:\\n  - Inadequate in representing large-scale discourse.\\n  - \u001b[0m\n",
       "\u001b[32mRetrieval is limited to shorter, contiguous passages, which fails to capture the holistic context needed for \u001b[0m\n",
       "\u001b[32manswering complex questions.\\n\\n### Solution\\n- **What solution does the paper propose?**\\n  The paper introduces \u001b[0m\n",
       "\u001b[32mRAPTOR, a recursive abstractive processing method for tree-organized retrieval. This involves recursively \u001b[0m\n",
       "\u001b[32membedding, clustering, and summarizing text chunks to build a hierarchical tree that provides both high-level and \u001b[0m\n",
       "\u001b[32mdetailed summaries. The model retrieves from this tree to incorporate varying levels of abstraction during \u001b[0m\n",
       "\u001b[32minference.\\n- **What inspired this idea? Was it influenced by other papers?**\\n  The idea was influenced by recent \u001b[0m\n",
       "\u001b[32madvances in hardware and algorithms that have expanded context handling capabilities and the effectiveness of \u001b[0m\n",
       "\u001b[32mhierarchical structures for capturing document semantics.\\n- **What theoretical basis supports this method?**\\n  \u001b[0m\n",
       "\u001b[32mThe method is theoretically supported by the concept of hierarchical data structures and embedding algorithms that \u001b[0m\n",
       "\u001b[32mallow effective clustering and retrieval. Techniques such as UMAP for dimensionality reduction and Gaussian Mixture\u001b[0m\n",
       "\u001b[32mModels for clustering underpin the theoretical foundation.\\n\\n### Experiment\\n- **How well does the experiment \u001b[0m\n",
       "\u001b[32mperform?**\\n  The experiments demonstrated that RAPTOR significantly outperforms traditional retrieval-augmented \u001b[0m\n",
       "\u001b[32mLMs on several tasks. Notably:\\n  - Achieves state-of-the-art results on question-answering tasks requiring \u001b[0m\n",
       "\u001b[32mcomplex, multi-step reasoning.\\n  - Improved performance on benchmarks like QuALITY, NarrativeQA, and QASPER.\\n- \u001b[0m\n",
       "\u001b[32m**What limitations or assumptions are associated with this method?**\\n  - Slight hallucinations in model-generated \u001b[0m\n",
       "\u001b[32msummaries \u001b[0m\u001b[32m(\u001b[0m\u001b[32m~4% found in an annotation study\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, though these do not propagate significantly and have minimal impact \u001b[0m\n",
       "\u001b[32mon task performance.\\n  - Requires efficient implementation to handle high computational demands, particularly with\u001b[0m\n",
       "\u001b[32mlarge texts and recursive summarization.\\n\\n### Innovation\\n- **What important or novel discoveries does this paper\u001b[0m\n",
       "\u001b[32mmake?**\\n  - Introduces the concept of a hierarchical tree structure for text retrieval, capturing both high-level \u001b[0m\n",
       "\u001b[32msummaries and detailed information.\\n  - Demonstrates the efficacy of combining summarization and hierarchical \u001b[0m\n",
       "\u001b[32mclustering in improving model performance in long-context, multi-step reasoning tasks.\\n  - Sets new \u001b[0m\n",
       "\u001b[32mstate-of-the-art performance benchmarks on multiple datasets and demonstrates significant improvements over \u001b[0m\n",
       "\u001b[32mtraditional methods.\\n\\n### Comments / Critique\\n- **Are there any limitations in this paper?**\\n  - While RAPTOR \u001b[0m\n",
       "\u001b[32mperforms well, the recursive summarization process can introduce minor hallucinations.\\n  - The method can be \u001b[0m\n",
       "\u001b[32mcomputationally intensive, requiring efficient scaling strategies.\\n- **Does the paper substantiate its claims \u001b[0m\n",
       "\u001b[32meffectively?**\\n  Yes, through controlled experiments and benchmarking against existing state-of-the-art methods. \u001b[0m\n",
       "\u001b[32mThe paper provides comprehensive evaluation results, showing consistent and statistically significant improvements \u001b[0m\n",
       "\u001b[32macross multiple datasets. Detailed ablation studies and qualitative analyses further support its claims.\"\u001b[0m,\n",
       "    \u001b[33msection_notes\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'ABSTRACT'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m'- The abstract discusses a novel methodology for enhancing retrieval-augmented \u001b[0m\n",
       "\u001b[32mlanguage models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n- The methodology helps LMs adapt better to changes in world knowledge and handle nuanced \u001b[0m\n",
       "\u001b[32minformation.\\n- Traditional methods that retrieve short, consecutive text segments from a corpus often neglect the \u001b[0m\n",
       "\u001b[32mbroader document context.\\n- The presented approach involves recursively embedding, clustering, and summarizing \u001b[0m\n",
       "\u001b[32mtext chunks to create a hierarchical tree structure of summaries.\\n- The RAPTOR model leverages this tree during \u001b[0m\n",
       "\u001b[32minference for better integration of document-level information at various abstraction levels.\\n- Experiments \u001b[0m\n",
       "\u001b[32mdemonstrate that recursive summaries significantly boost performance compared to traditional models across several \u001b[0m\n",
       "\u001b[32mtasks.\\n- Specifically, RAPTOR achieves state-of-the-art results in complex, multi-step question-answering \u001b[0m\n",
       "\u001b[32mtasks.\\n- RTPOR improves absolute accuracy on the QuALITY benchmark by 20% when paired with GPT-4.'\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'NO_QUOTES'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'INTRODUCTION'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m\"- Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have shown impressive performance and can store \u001b[0m\n",
       "\u001b[32mknowledge within their parameters, but updating them with new information is challenging.\\n- An alternative method \u001b[0m\n",
       "\u001b[32mis retrieval augmentation, which retrieves and presents relevant text chunks alongside questions to provide \u001b[0m\n",
       "\u001b[32mcontext.\\n- However, existing methods often fail to capture large-scale discourse structures needed for complex \u001b[0m\n",
       "\u001b[32mthematic questions.\\n- To address this, the paper introduces RAPTOR, a system that uses a hierarchical tree \u001b[0m\n",
       "\u001b[32mstructure to capture both high-level and low-level details of a text.\\n- RAPTOR clusters text chunks, generates \u001b[0m\n",
       "\u001b[32msummaries, and builds a tree to improve the LLM's ability to answer multi-level questions accurately and \u001b[0m\n",
       "\u001b[32mefficiently.\\n- The image describes the RAPTOR system, which enhances the performance of Large Language Models \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m by integrating a hierarchical structure to better manage and retrieve relevant information for complex \u001b[0m\n",
       "\u001b[32mqueries.\\n- Key insights and findings:\\n  - Limitations of Existing Methods: Traditional retrieval augmentation \u001b[0m\n",
       "\u001b[32mmethods struggle with large-scale discourse structures, making it difficult for LLMs to handle intricate thematic \u001b[0m\n",
       "\u001b[32mquestions effectively.\\n  - RAPTOR's Structure: RAPTOR utilizes a hierarchical tree model that captures both \u001b[0m\n",
       "\u001b[32mhigh-level and low-level details of text. This structure allows for organized representation and retrieval of \u001b[0m\n",
       "\u001b[32minformation.\\n  - Process Overview:\\n    - Clustering: Text is grouped into chunks, facilitating better \u001b[0m\n",
       "\u001b[32morganization.\\n    - Summarization by LLM: Each cluster is summarized, allowing for concise representation of the \u001b[0m\n",
       "\u001b[32minformation.\\n    - Tree Formation: These summaries create layers within the tree, with a root layer at the top and\u001b[0m\n",
       "\u001b[32mleaf layers at the bottom, enhancing clarity and retrieval accuracy.\\n  - Node Content: Each node in the RAPTOR \u001b[0m\n",
       "\u001b[32mtree contains:\\n    - An index for identification.\\n    - References to its child nodes.\\n    - A summary of the \u001b[0m\n",
       "\u001b[32mtext from child nodes.\\n    - Text embeddings that represent the content, making it easier to compare and retrieve \u001b[0m\n",
       "\u001b[32mrelevant information.\\n  - Enhanced Answering Capability: By structuring information hierarchically, RAPTOR \u001b[0m\n",
       "\u001b[32mimproves the LLM’s ability to answer complex, multi-level questions, ultimately leading to more accurate and \u001b[0m\n",
       "\u001b[32mcontextually rich responses.\\n- In summary, RAPTOR presents a novel framework for integrating hierarchical \u001b[0m\n",
       "\u001b[32morganization in LLMs, addressing existing shortcomings in retrieval processes for complex queries through \u001b[0m\n",
       "\u001b[32mstructured clustering and summarization.\"\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'> \"With the growing size of LLMs, they can serve standalone as very effective knowledge stores,\u001b[0m\n",
       "\u001b[32mwith facts encoded within their parameters... models can be further improved with fine-tuning on downstream \u001b[0m\n",
       "\u001b[32mtasks.\"\\n\\n**Explanation**: This quote highlights the primary question addressed in the paper, which is the \u001b[0m\n",
       "\u001b[32mimpressive performance and capabilities of Large Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as knowledge repositories and their \u001b[0m\n",
       "\u001b[32menhancement through fine-tuning.\\n\\n> \"Nevertheless, even a large model does not contain sufficient domain-specific\u001b[0m\n",
       "\u001b[32mknowledge for particular tasks and the world continues to change, invalidating facts in the \u001b[0m\n",
       "\u001b[32mLLM.\"\\n\\n**Explanation**: This quote emphasizes a major problem the paper addresses: the limitations of LLMs in \u001b[0m\n",
       "\u001b[32mhandling evolving and domain-specific knowledge, which necessitates frequent updates that are challenging to \u001b[0m\n",
       "\u001b[32mimplement.\\n\\n> \"To address this, we design an indexing and retrieval system that uses a tree structure to capture \u001b[0m\n",
       "\u001b[32mboth high-level and low-level details about a text... This structure enables RAPTOR to load into an LLM’s context \u001b[0m\n",
       "\u001b[32mchunks representing the text at different levels so that it can effectively and efficiently answer questions at \u001b[0m\n",
       "\u001b[32mdifferent levels.\"\\n\\n**Explanation**: This quote describes the proposed solution, RAPTOR, which is an innovative \u001b[0m\n",
       "\u001b[32mindexing and retrieval system using a tree structure that allows for effective multi-level information retrieval, \u001b[0m\n",
       "\u001b[32maddressing the limitation of current retrieval-augmented methods in handling large-scale discourse structure.'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/figure-2-1.jpg'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'RELATED WORK'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m\"- The section discusses the importance of retrieval systems despite advancements in \u001b[0m\n",
       "\u001b[32mhandling long contexts by current models.\\n- It highlights that models underperform with long contexts due to \u001b[0m\n",
       "\u001b[32munderutilization and high costs.\\n- Retrieval-augmented language models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRALMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have improved in components such as\u001b[0m\n",
       "\u001b[32mthe retriever, reader, and end-to-end training.\\n- RALM methods have evolved from traditional techniques like \u001b[0m\n",
       "\u001b[32mTF-IDF and BM25 to deep learning-based strategies.\\n- Techniques like FiD and RETRO are notable approaches \u001b[0m\n",
       "\u001b[32mproviding robust retrieval mechanisms.\\n- End-to-end systems like Atlas, REALM, and RAG offer advancements in \u001b[0m\n",
       "\u001b[32mefficiency.\\n- The section also covers new retrieval models like Joint Passage Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mJPR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, Dense Hierarchical \u001b[0m\n",
       "\u001b[32mRetrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mDHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and Hybrid Hierarchical Retrieval \u001b[0m\u001b[32m(\u001b[0m\u001b[32mHHR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, which improve accuracy.\\n- Issues like the limitations of\u001b[0m\n",
       "\u001b[32mstandard chunking approaches and the potential of recursive summarization techniques are also discussed.\\n- Models \u001b[0m\n",
       "\u001b[32msuch as Gao et al.'s superficial summaries and Wu et al.’s recursive-abstractive summarization, along with \u001b[0m\n",
       "\u001b[32mLlamaIndex, are explored for addressing these limitations by providing varying levels of detail without losing \u001b[0m\n",
       "\u001b[32mcritical interdependencies in the text.\"\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'> \"However, as Liu et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2023\u001b[0m\u001b[32m)\u001b[0m\u001b[32m and Sun et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2021\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have noted, models tend to underutilize \u001b[0m\n",
       "\u001b[32mlong-range context and see diminishing performance as context length increases, especially when pertinent \u001b[0m\n",
       "\u001b[32minformation is embedded within a lengthy context.\"\\n\\n**Explanation**: This quote highlights a critical problem in \u001b[0m\n",
       "\u001b[32mcurrent deep learning models—their inefficiency in utilizing long-range context. It underscores the necessity for \u001b[0m\n",
       "\u001b[32mretrieval systems to handle knowledge-intensive tasks effectively.\\n\\n> \"Some recent work proposes using large \u001b[0m\n",
       "\u001b[32mlanguage models as retrievers due to their ability to memorize extensive knowledge \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYu et al., 2022; Sun et al., \u001b[0m\n",
       "\u001b[32m2022\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\"\\n\\n**Explanation**: This quote reveals a significant shift in retrieval methods, suggesting the use of \u001b[0m\n",
       "\u001b[32mlarge language models as retrievers. This represents an innovative approach leveraging the models\\' extensive \u001b[0m\n",
       "\u001b[32mknowledge memorization capacities.\\n\\n> \"Despite a diversity in methods, the retrieving components of models \u001b[0m\n",
       "\u001b[32mpredominantly rely on standard approaches, i.e., chunking corpora and encoding with BERT-based retrievers... \u001b[0m\n",
       "\u001b[32mcontiguous segmentation might not capture the complete semantic depth of the text.\"\\n\\n**Explanation**: This quote \u001b[0m\n",
       "\u001b[32mpoints out potential shortcomings in current retrieval techniques, emphasizing the limitations of standard chunking\u001b[0m\n",
       "\u001b[32mand encoding methods. This critical insight challenges the community to develop more nuanced and context-aware \u001b[0m\n",
       "\u001b[32mretrieval systems.'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'METHODS'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m\"- The section describes the methods used in the RAPTOR system, which is designed to \u001b[0m\n",
       "\u001b[32mhandle long texts with multiple subtopics by organizing information into a recursive tree structure.\\n- This is \u001b[0m\n",
       "\u001b[32machieved through several steps:\\n    - **Text Segmentation**: The text is divided into contiguous chunks, ensuring \u001b[0m\n",
       "\u001b[32msemantic coherence by not splitting sentences.\\n    - **Embedding**: Each chunk is embedded using SBERT, forming \u001b[0m\n",
       "\u001b[32mthe leaf nodes of the tree.\\n    - **Clustering**: Text chunks with similar content are grouped using a soft \u001b[0m\n",
       "\u001b[32mclustering algorithm based on Gaussian Mixture Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mGMMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n    - **Summarization**: The clusters are summarized\u001b[0m\n",
       "\u001b[32musing a language model, such as gpt-3.5-turbo. This process of embedding, clustering, and summarizing repeats \u001b[0m\n",
       "\u001b[32mrecursively until further clustering is no longer feasible, forming a multi-layered tree.\\n- The RAPTOR system is \u001b[0m\n",
       "\u001b[32mcomputationally efficient, scaling linearly with respect to build time and token usage, making it suitable for \u001b[0m\n",
       "\u001b[32mlarge and complex corpora.\\n- Two query strategies—tree traversal and collapsed tree—are introduced to navigate the\u001b[0m\n",
       "\u001b[32mhierarchical structure.\\n- For clustering, the method utilizes GMMs, providing flexibility by allowing nodes to \u001b[0m\n",
       "\u001b[32mbelong to multiple clusters.\\n- UMAP is used for dimensionality reduction to improve clustering in high-dimensional\u001b[0m\n",
       "\u001b[32mspaces.\\n- The optimal number of clusters is determined using the Bayesian Information Criterion \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBIC\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n- In the \u001b[0m\n",
       "\u001b[32msummarization phase, gpt-3.5-turbo generates concise summaries of the clustered text.\\n- Despite occasional minor \u001b[0m\n",
       "\u001b[32mhallucinations in the summaries, they do not significantly impact overall performance in question-answering \u001b[0m\n",
       "\u001b[32mtasks.\\n- Further details about scalability, comparison with other methods, summarization compression, and handling\u001b[0m\n",
       "\u001b[32mof hallucinations are available in the paper's appendices.\"\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'> \"RAPTOR addresses the issue of semantic depth and connection in reading by building a \u001b[0m\n",
       "\u001b[32mrecursive tree structure that balances broader thematic comprehension with granular details and which allows nodes \u001b[0m\n",
       "\u001b[32mto be grouped based on semantic similarity not just order in the text.\"\\n\\n**Explanation**: This quote is important\u001b[0m\n",
       "\u001b[32mas it highlights the primary problem RAPTOR aims to solve: enhancing semantic depth and connectivity in long texts \u001b[0m\n",
       "\u001b[32mby utilizing a recursive tree structure. This structure aids in understanding both broad themes and specific \u001b[0m\n",
       "\u001b[32mdetails.\\n\\n> \"One of the unique aspects of our clustering approach is the use of soft clustering, where nodes can \u001b[0m\n",
       "\u001b[32mbelong to multiple clusters without requiring a fixed number of clusters. This flexibility is essential because \u001b[0m\n",
       "\u001b[32mindividual text segments often contain information relevant to various topics, thereby warranting their inclusion \u001b[0m\n",
       "\u001b[32min multiple summaries.\"\\n\\n**Explanation**: This quote is important because it describes a key feature of RAPTOR\\'s\u001b[0m\n",
       "\u001b[32mmethod—soft clustering via Gaussian Mixture Models. This method provides flexibility by allowing text segments to \u001b[0m\n",
       "\u001b[32mbelong to multiple clusters, addressing the complexity of information that often overlaps different topics.\\n\\n> \u001b[0m\n",
       "\u001b[32m\"An important aspect of RAPTOR is its computational efficiency. The system scales linearly in terms of both build \u001b[0m\n",
       "\u001b[32mtime and token expenditure, making it suitable for processing large and complex corpora.\"\\n\\n**Explanation**: This \u001b[0m\n",
       "\u001b[32mquote underscores the practical significance of RAPTOR by pointing out its computational efficiency. The linear \u001b[0m\n",
       "\u001b[32mscalability in terms of computational resources means that RAPTOR is well-suited for handling extensive and \u001b[0m\n",
       "\u001b[32mintricate corpora, which is critical for real-world applications.'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'EXPERIMENTS'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m'- The section titled \"EXPERIMENTS\" details the evaluation of RAPTOR\\'s performance on \u001b[0m\n",
       "\u001b[32mthree distinct question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n- **NarrativeQA** involves questions\u001b[0m\n",
       "\u001b[32mderived from books and movie transcripts and assesses the model’s comprehension of longer texts. Performance is \u001b[0m\n",
       "\u001b[32mmeasured using BLEU, ROUGE, and METEOR metrics.\\n- **QASPER** consists of questions about NLP papers, challenging \u001b[0m\n",
       "\u001b[32mthe model\\'s ability to extract and synthesize information. The dataset includes four types of answers and is \u001b[0m\n",
       "\u001b[32mevaluated using F1 accuracy.\\n- **QuALITY** includes multiple-choice questions with context passages, measuring \u001b[0m\n",
       "\u001b[32mreasoning over medium-length documents, and includes a particularly difficult subset called QuALITY-HARD.\\n- The \u001b[0m\n",
       "\u001b[32msection also presents controlled baseline comparisons using UnifiedQA 3B reader and various embedding models with \u001b[0m\n",
       "\u001b[32mand without RAPTOR\\'s tree structure.\\n- Results indicate that RAPTOR enhances performance across all datasets and \u001b[0m\n",
       "\u001b[32membedding models when compared to SBERT, BM25, and DPR alone.\\n- Further comparisons using GPT-3, GPT-4, and \u001b[0m\n",
       "\u001b[32mUnifiedQA on the QASPER dataset demonstrate that RAPTOR consistently outperforms these benchmarks, leveraging \u001b[0m\n",
       "\u001b[32mhigher-level summary nodes for superior information synthesis.\\n- The \"EXPERIMENTS\" section assesses RAPTOR’s \u001b[0m\n",
       "\u001b[32meffectiveness across three specific question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Datasets \u001b[0m\n",
       "\u001b[32mOverview**:\\n    - **NarrativeQA**: Focuses on comprehension of longer texts, evaluating models primarily using \u001b[0m\n",
       "\u001b[32mBLEU, ROUGE, and METEOR metrics.\\n    - **QASPER**: Tests the ability to extract and synthesize information from \u001b[0m\n",
       "\u001b[32mNLP papers, with evaluation based on F1 accuracy and various answer types.\\n    - **QuALITY**: Features \u001b[0m\n",
       "\u001b[32mmultiple-choice questions related to context passages, particularly assessing reasoning capabilities, including a \u001b[0m\n",
       "\u001b[32mchallenging subset called QuALITY-HARD.\\n  - **Performance Metrics**:\\n    - The metrics used for evaluation \u001b[0m\n",
       "\u001b[32minclude ROUGE, BLEU \u001b[0m\u001b[32m(\u001b[0m\u001b[32m1 and 4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and METEOR, which measure different aspects of generated text relevance and \u001b[0m\n",
       "\u001b[32mquality.\\n  - **Controlled Comparisons**:\\n    - The experiments include evaluations against various baseline \u001b[0m\n",
       "\u001b[32mmodels: SBERT, BM25, and DPR, both with and without RAPTOR’s tree structure.\\n    - RAPTOR consistently enhances \u001b[0m\n",
       "\u001b[32mperformance across all models and datasets.\\n  - **Key Findings**:\\n    - Models incorporating RAPTOR \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSBERT with \u001b[0m\n",
       "\u001b[32mRAPTOR, BM25 with RAPTOR, and DPR with RAPTOR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m outperform their counterparts without it.\\n    - For example, SBERT \u001b[0m\n",
       "\u001b[32mwith RAPTOR achieves a ROUGE score of 30.87% compared to 29.26% without it, demonstrating RAPTOR\\'s \u001b[0m\n",
       "\u001b[32meffectiveness.\\n    - The enhancements are evident in all metrics, with RAPTOR facilitating improved information \u001b[0m\n",
       "\u001b[32msynthesis and understanding.\\n  - **Comparison with Advanced Models**:\\n    - When compared to advanced models like\u001b[0m\n",
       "\u001b[32mGPT-3 and GPT-4 on the QASPER dataset, RAPTOR shows superior performance, leveraging the structure of higher-level \u001b[0m\n",
       "\u001b[32msummary nodes for better outcomes.\\n  - Overall, RAPTOR significantly boosts performance in question-answering \u001b[0m\n",
       "\u001b[32mtasks, demonstrating its utility and effectiveness in enhancing comprehension and synthesis of information across \u001b[0m\n",
       "\u001b[32mvaried datasets.\\n- The section titled \"EXPERIMENTS\" evaluates the performance of the RAPTOR model across three \u001b[0m\n",
       "\u001b[32mdifferent question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Datasets Overview**:\\n    - \u001b[0m\n",
       "\u001b[32m**NarrativeQA**: Focuses on understanding longer narratives, derived from books and movies. Performance is assessed\u001b[0m\n",
       "\u001b[32musing BLEU, ROUGE, and METEOR metrics.\\n    - **QASPER**: Comprises questions related to NLP papers, emphasizing \u001b[0m\n",
       "\u001b[32mthe model\\'s ability to extract and synthesize information. Evaluated using F1 accuracy across four answer types.\\n\u001b[0m\n",
       "\u001b[32m- **QuALITY**: Involves multiple-choice questions based on context passages, measuring reasoning capabilities. A \u001b[0m\n",
       "\u001b[32mchallenging subset, QuALITY-HARD, is also included.\\n  - **Performance Comparison**:\\n    - RAPTOR\\'s integration \u001b[0m\n",
       "\u001b[32mconsistently improves performance when combined with other models \u001b[0m\u001b[32m(\u001b[0m\u001b[32me.g., SBERT, BM25, DPR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m compared to their \u001b[0m\n",
       "\u001b[32mstandalone performances.\\n    - For example, SBERT with RAPTOR achieved an accuracy of 56.6% in the QuALITY \u001b[0m\n",
       "\u001b[32mdataset, while SBERT without RAPTOR had a slightly lower accuracy of 54.9%.\\n    - Similar enhancements are noted \u001b[0m\n",
       "\u001b[32macross all models tested, indicating that RAPTOR effectively enhances model capabilities.\\n  - **Benchmarking \u001b[0m\n",
       "\u001b[32mAgainst Existing Models**:\\n    - Further evaluations using state-of-the-art models like GPT-3, GPT-4, and \u001b[0m\n",
       "\u001b[32mUnifiedQA demonstrate that RAPTOR outperforms these benchmarks on the QASPER dataset.\\n    - The model appears to \u001b[0m\n",
       "\u001b[32mexcel in synthesizing information by leveraging higher-level summary nodes, contributing to improved answer \u001b[0m\n",
       "\u001b[32mextraction and synthesis.\\n  - **Quantitative Results**:\\n    - The tabulated results show RAPTOR\\'s combination \u001b[0m\n",
       "\u001b[32mwith SBERT, BM25, and DPR results in higher metrics for both QuALITY and QASPER datasets, highlighting RAPTOR\\'s \u001b[0m\n",
       "\u001b[32mbeneficial impact on model performance.\\n    - The F1 scores for QASPER also reveal that RAPTOR-led combinations \u001b[0m\n",
       "\u001b[32myield better performance, emphasizing its ability to enhance answer extraction capabilities.\\n  - Overall, the \u001b[0m\n",
       "\u001b[32mexperiments illustrate RAPTOR\\'s efficacy in improving the performance of existing models across various \u001b[0m\n",
       "\u001b[32mquestion-answering tasks, showcasing its potential as a valuable component in natural language processing \u001b[0m\n",
       "\u001b[32mapplications.\\n- The section titled \"EXPERIMENTS\" provides a comprehensive evaluation of the RAPTOR model across \u001b[0m\n",
       "\u001b[32mthree distinct question-answering datasets: NarrativeQA, QASPER, and QuALITY.\\n  - **Dataset Evaluations**:\\n    - \u001b[0m\n",
       "\u001b[32m**NarrativeQA**: Assesses comprehension of lengthy texts through questions related to books and movie transcripts. \u001b[0m\n",
       "\u001b[32mPerformance is evaluated using metrics like BLEU, ROUGE, and METEOR.\\n    - **QASPER**: Focuses on questions \u001b[0m\n",
       "\u001b[32mderived from NLP papers, testing the model\\'s ability to extract and synthesize information from these sources. It \u001b[0m\n",
       "\u001b[32muses F1 accuracy for its evaluations.\\n    - **QuALITY**: Involves multiple-choice questions with context passages,\u001b[0m\n",
       "\u001b[32memphasizing reasoning over medium-length documents. A particularly challenging subset, QuALITY-HARD, is also \u001b[0m\n",
       "\u001b[32mincluded to assess performance under difficult conditions.\\n  - **Baseline Comparisons**:\\n    - The experiments \u001b[0m\n",
       "\u001b[32mprovide controlled comparisons against various existing models, including UnifiedQA 3B and different embedding \u001b[0m\n",
       "\u001b[32mmodels, contrasting their performance with and without RAPTOR\\'s tree structure.\\n    - RAPTOR consistently \u001b[0m\n",
       "\u001b[32menhances performance across all evaluated datasets and embedding models, outperforming established methods like \u001b[0m\n",
       "\u001b[32mSBERT, BM25, and DPR.\\n  - **Benchmark Performances**:\\n    - On the QASPER dataset, RAPTOR outperformed large \u001b[0m\n",
       "\u001b[32mlanguage models, including GPT-3 and GPT-4, as well as the UnifiedQA model.\\n    - The F1 scores demonstrate that \u001b[0m\n",
       "\u001b[32mRAPTOR achieves superior results, largely due to its utilization of higher-level summary nodes which enhance its \u001b[0m\n",
       "\u001b[32mability to synthesize information effectively.\\n  - **Performance Metrics**:\\n    - Notably, RAPTOR achieves F1 \u001b[0m\n",
       "\u001b[32mscores of 53.1 with GPT-3, 55.7 with GPT-4, and 36.6 with UnifiedQA, indicating its strong competency in handling \u001b[0m\n",
       "\u001b[32mthe tasks presented across different datasets.\\n  - Overall, these findings highlight RAPTOR\\'s effectiveness in \u001b[0m\n",
       "\u001b[32mimproving question-answering capabilities through its advanced structural approach and outperforming multiple \u001b[0m\n",
       "\u001b[32mestablished models.'\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'> \"We measure RAPTOR’s performance across three question-answering datasets: Narra-tiveQA, \u001b[0m\n",
       "\u001b[32mQASPER, and QuALITY.\"\\n\\n**Explanation**: This quote is important because it identifies the datasets used to \u001b[0m\n",
       "\u001b[32mevaluate the performance of RAPTOR, establishing the context for the experiments.\\n\\n> \"Controlled Baseline \u001b[0m\n",
       "\u001b[32mComparisons We first present controlled comparisons using the UnifiedQA 3B as the reader, with SBERT \u001b[0m\u001b[32m(\u001b[0m\u001b[32mReimers & \u001b[0m\n",
       "\u001b[32mGurevych, 2019\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, BM25 \u001b[0m\u001b[32m(\u001b[0m\u001b[32mRobertson et al., 1995; 2009\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, and DPR \u001b[0m\u001b[32m(\u001b[0m\u001b[32mKarpukhin et al., 2020\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as the embedding models with\u001b[0m\n",
       "\u001b[32mand without the RAPTOR tree structure, on three datasets: QASPER, NarrativeQA, and QuALITY.\"\\n\\n**Explanation**: \u001b[0m\n",
       "\u001b[32mThis quote explains the methodology of the controlled baseline comparisons, detailing the embedding models and \u001b[0m\n",
       "\u001b[32mdatasets used. It highlights the experimental setup to verify RAPTOR’s performance.\\n\\n> \"As shown in Table 3, \u001b[0m\n",
       "\u001b[32mRAPTOR consistently outperforms BM25 and DPR across all three Language Models on the QASPER dataset. RAPTOR’s F-1 \u001b[0m\n",
       "\u001b[32mMatch scores are 53.1%, 55.7%, and 36.6% when using GPT-3, GPT-4, and UnifiedQA, respectively.\"\\n\\n**Explanation**:\u001b[0m\n",
       "\u001b[32mThis quote is crucial as it emphasizes RAPTOR\\'s superior performance over existing methods \u001b[0m\u001b[32m(\u001b[0m\u001b[32mBM25 and DPR\u001b[0m\u001b[32m)\u001b[0m\u001b[32m across \u001b[0m\n",
       "\u001b[32mdifferent language models, showcasing significant improvements in F-1 Match scores on the QASPER dataset.'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\n",
       "                \u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-7-1.jpg'\u001b[0m,\n",
       "                \u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-8-2.jpg'\u001b[0m,\n",
       "                \u001b[32m'/var/folders/dl/r5b6b73j7jggfjshyl62v7qh0000gn/T/tmpy1qm449a/table-8-3.jpg'\u001b[0m\n",
       "            \u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'CONCLUSION'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m'- The paper introduces RAPTOR, an innovative tree-based retrieval system designed to \u001b[0m\n",
       "\u001b[32menhance the retrieval capabilities of large language models by incorporating contextual information at multiple \u001b[0m\n",
       "\u001b[32mabstraction levels.\\n- RAPTOR utilizes recursive clustering and summarization to build a hierarchical tree \u001b[0m\n",
       "\u001b[32mstructure, effectively synthesizing information from different parts of the retrieval corpus.\\n- In the query \u001b[0m\n",
       "\u001b[32mphase, this structure aids in more efficient information retrieval.\\n- Experimental results indicate that RAPTOR \u001b[0m\n",
       "\u001b[32msurpasses traditional retrieval methods and achieves new performance standards in multiple question-answering \u001b[0m\n",
       "\u001b[32mtasks.'\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m'NO_QUOTES'\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mSectionNote\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mheader\u001b[0m=\u001b[32m'HALLUCINATION ANALYSIS'\u001b[0m,\n",
       "            \u001b[33msummary_content\u001b[0m=\u001b[32m\"- The section investigates the presence and impact of hallucinations in summaries \u001b[0m\n",
       "\u001b[32mgenerated by the RAPTOR model using gpt-3.5-turbo.\\n- Hallucinations refer to inaccuracies wherein the model adds \u001b[0m\n",
       "\u001b[32minformation not present in the source text.\\n- Researchers randomly sampled 150 nodes from 40 stories and manually \u001b[0m\n",
       "\u001b[32mevaluated them.\\n- They found a 4% hallucination rate, typically involving minor additions or incorrect \u001b[0m\n",
       "\u001b[32mextrapolations that did not significantly alter the text's thematic interpretation.\\n- These hallucinations did not\u001b[0m\n",
       "\u001b[32mpropagate to higher summary layers.\\n- Hallucinations did not impact the performance in question-answering \u001b[0m\n",
       "\u001b[32mtasks.\\n- Hallucinations are not a critical issue for the RAPTOR model's summarization capabilities.\"\u001b[0m,\n",
       "            \u001b[33mquotes\u001b[0m=\u001b[32m\"> 'To assess the quality and accuracy of the summarizations within our RAPTOR model, we \u001b[0m\n",
       "\u001b[32mconducted an analysis focusing on hallucinations in the generated summaries.'\\n\\n**Explanation**: This quote is \u001b[0m\n",
       "\u001b[32mimportant as it outlines the primary objective of this section, which is to evaluate the accuracy of the RAPTOR \u001b[0m\n",
       "\u001b[32mmodel's summarizations by examining hallucinations.\\n\\n> 'Out of the 150 nodes sampled, 4% \u001b[0m\u001b[32m(\u001b[0m\u001b[32m6 nodes\u001b[0m\u001b[32m)\u001b[0m\u001b[32m contained some\u001b[0m\n",
       "\u001b[32mform of hallucination. Most commonly, these hallucinations originated from the model adding minor information \u001b[0m\n",
       "\u001b[32mpossibly from its training data that was not present in the text being summarized, or from incorrectly \u001b[0m\n",
       "\u001b[32mextrapolating some information when creating the summary.'\\n\\n**Explanation**: This quote highlights the key \u001b[0m\n",
       "\u001b[32mfindings regarding the prevalence and nature of hallucinations in the model's summaries. It gives specific \u001b[0m\n",
       "\u001b[32mstatistics and describes the common causes of the inaccuracies.\\n\\n> 'In our findings, hallucinations had no \u001b[0m\n",
       "\u001b[32mdiscernible impact on the performance of QA tasks. This suggests that hallucination is not a major concern for the \u001b[0m\n",
       "\u001b[32msummarization component in our RAPTOR architecture.'\\n\\n**Explanation**: This quote emphasizes a crucial outcome of\u001b[0m\n",
       "\u001b[32mthe analysis, indicating that despite the presence of some hallucinations, their impact on the overall QA tasks is \u001b[0m\n",
       "\u001b[32mnegligible. This insight is significant for understanding the practical implications of the model's performance.\"\u001b[0m,\n",
       "            \u001b[33mimage_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "            \u001b[33mtable_paths\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_result = paper_summarizer.summarize()\n",
    "print(summary_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
