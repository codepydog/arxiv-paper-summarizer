{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AI Summarizer for arXiv papers.\"\"\"\n",
    "\n",
    "import tempfile\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from pydantic import TypeAdapter\n",
    "from unstructured.documents.elements import Element\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "from arxiv_paper_summarizer.arxiv import fetch_papers_by_url, load_paper_as_file_by_url\n",
    "from arxiv_paper_summarizer.prompt_function import openai_prompt\n",
    "from arxiv_paper_summarizer.types import (\n",
    "    LLM_TYPE,\n",
    "    ExtractedSectionResult,\n",
    "    ImagePath,\n",
    "    Paper,\n",
    "    SectionInfo,\n",
    "    SectionNote,\n",
    "    SummaryResult,\n",
    ")\n",
    "from arxiv_paper_summarizer.utils import encode_image, extract_json_content, get_env_var\n",
    "\n",
    "try:\n",
    "    from langfuse.openai import OpenAI\n",
    "except ImportError:\n",
    "    from openai import OpenAI\n",
    "\n",
    "\n",
    "class ArxivPaperSummarizer:\n",
    "    \"\"\"Summarizer for arXiv papers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        arxiv_url: str,\n",
    "        llm: LLM_TYPE | None = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the summarizer.\"\"\"\n",
    "        self._arxiv_url = arxiv_url\n",
    "        self._llm = llm\n",
    "\n",
    "        self._paper: Paper | None = None\n",
    "        self._elements: list[Element] | None = None\n",
    "        self._image_path_list: list[ImagePath] = []\n",
    "\n",
    "        self._section_notes: list[SectionNote] = []\n",
    "        self._translated_section_notes: list[SectionNote] = []\n",
    "        self._image_output_dir = tempfile.mkdtemp()\n",
    "\n",
    "        self._post_init()\n",
    "\n",
    "    def _post_init(self):\n",
    "        self._paper = self.get_paper()\n",
    "        self._elements = self.get_partition_elements()\n",
    "        self._image_path_list = self.get_image_path_list()\n",
    "\n",
    "    def summarize(self) -> SummaryResult:\n",
    "        \"\"\"Summarize the arXiv paper.\"\"\"\n",
    "        section_list = self.extract_section_list(self.paper.text)\n",
    "        section_info_list = self.get_section_info_list(section_list)\n",
    "        keynote = self.extract_keynote()\n",
    "        section_notes = self.extract_section_note_list(section_info_list)\n",
    "        return SummaryResult(keynote=keynote, section_notes=section_notes)\n",
    "\n",
    "    def extract_keynote(self) -> str:\n",
    "        try:\n",
    "            return self._extract_keynote(self.paper.text)  # type: ignore\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error in extracting keynote: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def extract_section_note_list(self, section_info_list: list[SectionInfo]) -> list[SectionNote]:\n",
    "        try:\n",
    "            section_note_list = [self._write_section_note(section) for section in section_info_list]\n",
    "            return TypeAdapter(list[SectionNote]).validate_python(section_note_list)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error in writing comprehensive analysis note: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _write_section_note(self, section: SectionInfo) -> SectionNote:\n",
    "        \"\"\"Summarize the section.\"\"\"\n",
    "        summary = self.summarize_section(text=section.content, title=section.title)  # type: ignore\n",
    "        img_summaries = [self.summarize_images(img_enc, summary) for img_enc in section.image_encoding_str_list]  # type: ignore\n",
    "        structured_section_summary = self.organize_section_summary(summary, img_summaries)  # type: ignore\n",
    "        quotes = self.extract_section_quotes(section.content, title=section.title)  # type: ignore\n",
    "        return SectionNote(\n",
    "            header=section.title,\n",
    "            summary_content=structured_section_summary,\n",
    "            quotes=quotes,\n",
    "            image_path=section.image_paths,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def arxiv_url(self) -> str:\n",
    "        \"\"\"Return the arXiv URL.\"\"\"\n",
    "        if not self._arxiv_url:\n",
    "            raise ValueError(\"arXiv URL is required.\")\n",
    "        return self._arxiv_url\n",
    "\n",
    "    @property\n",
    "    def llm(self) -> LLM_TYPE:\n",
    "        \"\"\"Return the language model.\"\"\"\n",
    "        return self._llm or self.get_llm()\n",
    "\n",
    "    @property\n",
    "    def paper(self) -> Paper:\n",
    "        \"\"\"Return the arXiv paper.\"\"\"\n",
    "        if self._paper is None:\n",
    "            self._paper = self.get_paper()\n",
    "        return self._paper\n",
    "\n",
    "    @property\n",
    "    def image_path_list(self) -> list[ImagePath]:\n",
    "        \"\"\"Return the list of image paths.\"\"\"\n",
    "        return self._image_path_list\n",
    "\n",
    "    @property\n",
    "    def elements(self) -> list[Element]:\n",
    "        \"\"\"Return the partition elements of the paper.\"\"\"\n",
    "        if self._elements is None:\n",
    "            self._elements = self.get_partition_elements()\n",
    "        return self._elements\n",
    "\n",
    "    def get_llm(self) -> LLM_TYPE:\n",
    "        \"\"\"Get the language model.\"\"\"\n",
    "        return OpenAI(\n",
    "            api_key=get_env_var(\"OPENAI_API_KEY\"),\n",
    "            base_url=get_env_var(\"OPENAI_BASE_URL\"),\n",
    "        )\n",
    "\n",
    "    def get_paper(self) -> Paper:\n",
    "        \"\"\"Get the arXiv paper.\"\"\"\n",
    "        papers = fetch_papers_by_url(self.arxiv_url)\n",
    "        if not papers:\n",
    "            raise ValueError(f\"No paper found for URL '{self.arxiv_url}'.\")\n",
    "\n",
    "        if len(papers) > 1:\n",
    "            warnings.warn(f\"Multiple papers found for URL '{self.arxiv_url}'. Using the first one. \")\n",
    "\n",
    "        return papers[0]\n",
    "\n",
    "    def get_partition_elements(self) -> list[Element]:\n",
    "        \"\"\"Get the partition elements of the paper.\"\"\"\n",
    "        file = load_paper_as_file_by_url(self.arxiv_url)\n",
    "        elements = partition_pdf(\n",
    "            file=file,\n",
    "            strategy=\"hi_res\",\n",
    "            infer_table_structure=True,\n",
    "            extract_images_in_pdf=True,\n",
    "            extract_image_block_types=[\"Image\", \"Table\"],\n",
    "            extract_image_block_to_payload=False,\n",
    "            extract_image_block_output_dir=self._image_output_dir,\n",
    "        )\n",
    "        return elements\n",
    "\n",
    "    def get_image_path_list(self) -> list[ImagePath]:\n",
    "        \"\"\"Get the list of image paths.\"\"\"\n",
    "        image_path_list: list[ImagePath] = []\n",
    "        for element in self.elements:\n",
    "            element_dict = element.to_dict()\n",
    "            if element_dict[\"type\"] == \"Image\" or element_dict[\"type\"] == \"Table\":\n",
    "                img_path = element_dict[\"metadata\"][\"image_path\"]\n",
    "                filename = Path(img_path).stem\n",
    "                image_path_list.append(ImagePath(path=str(img_path), filename=str(filename)))\n",
    "        return image_path_list\n",
    "\n",
    "    def get_image_filename_set(self) -> set[str]:\n",
    "        \"\"\"Get the set of image paths.\"\"\"\n",
    "        return set([image_path.filename for image_path in self.image_path_list])\n",
    "\n",
    "    def get_section_info_list(self, section_list: list[ExtractedSectionResult]) -> list[SectionInfo]:\n",
    "        \"\"\"Get the section info of the paper.\"\"\"\n",
    "        result = []\n",
    "        for section in section_list:\n",
    "            if section.content == \"\":\n",
    "                continue\n",
    "\n",
    "            image_encoding_str_list = []\n",
    "            for filename in section.ref_fig + section.ref_tb:\n",
    "                if filename not in self.get_image_filename_set():\n",
    "                    continue\n",
    "                image_path = Path(self._image_output_dir) / f\"{filename}.jpg\"\n",
    "                image_encoding_str_list.append(encode_image(str(image_path)))\n",
    "\n",
    "            result.append(\n",
    "                SectionInfo(\n",
    "                    title=section.section,\n",
    "                    content=section.content,\n",
    "                    image_encoding_str_list=image_encoding_str_list,\n",
    "                    image_paths=[image_path.path for image_path in self.image_path_list],\n",
    "                )\n",
    "            )\n",
    "        return TypeAdapter(list[SectionInfo]).validate_python(result)\n",
    "\n",
    "    def extract_section_list(self, text: str) -> list[ExtractedSectionResult]:\n",
    "        \"\"\"Extract the sections from the content of paper.\"\"\"\n",
    "        json_str = self._extract_paper_sections(text)  # type: ignore\n",
    "        json_obj = extract_json_content(json_str)\n",
    "        return TypeAdapter(list[ExtractedSectionResult]).validate_python(json_obj)\n",
    "\n",
    "    @openai_prompt(\n",
    "        (\"system\", \"You are a helpful AI assistant.\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"## Task:\\n\"\n",
    "            \"Given the content of a paper in triple backticks, organize each section into a JSON object format where each element contains:\\n\"\n",
    "            \"- `section`: The name of the section, capturing the main topic or heading of the section.\\n\"\n",
    "            \"- `content`: The full content of the section, presented exactly as in the paper without reduction or summarization.\\n\"\n",
    "            \"- `ref_fig`: A list of figure references in this section. \"\n",
    "            \"Each reference must follow the format 'figure-<page>-<number>' (e.g., 'figure-20-7' for the seventh figure on page 20).\\n\"\n",
    "            \"- `ref_tb`: A list of table references in this section. \"\n",
    "            \"Each reference must follow the format 'table-<page>-<number>' (e.g., 'table-15-3' for the third table on page 15).\\n\\n\"\n",
    "            \"Ensure that each section is represented as a structured JSON object, without reducing or summarizing the content. \"\n",
    "            \"Do not include the references section.\\n\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            '### Response Format:\\n```json\\n[{{\"section\": \"str\", \"content\": \"str\", \"ref_fig\": [\"str\"], \"ref_tb\": [\"str\"]}}]\\n```',\n",
    "        ),\n",
    "        (\"user\", \"Paper content: ```{text}```\"),\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "    )\n",
    "    def _extract_paper_sections(self, text: str) -> str: ...  # type: ignore[empty-body]\n",
    "\n",
    "    @openai_prompt(\n",
    "        (\"system\", \"You are a AI Research.\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"I am reading a machine learning and deep learning paper and will provide you with a section of its content. \"\n",
    "            \"Provide a brief summary of the section.\",\n",
    "        ),\n",
    "        (\"user\", \"## Response Format\\n## {title}\\n```{text}```\"),\n",
    "        (\"user\", \"## Title: {title}\\nContent:\\n```\\n{text}\\n```\"),\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "    def summarize_section(self, text: str, title: str) -> str: ...  # type: ignore[empty-body]\n",
    "\n",
    "    @openai_prompt(\n",
    "        (\"system\", \"You are an AI research assistant.\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"## Task\\n\"\n",
    "            \"I am reading a machine learning and deep learning paper and will provide you with a section of its content. \"\n",
    "            \"Extract only the essential quotes that capture the key information from this section, as follows:\\n\"\n",
    "            \"- Include quotes that highlight the primary problem or question addressed.\\n\"\n",
    "            \"- Add quotes describing any proposed methods or solutions, along with theoretical foundations or significant insights.\\n\"\n",
    "            \"- Provide quotes on any major findings or important points emphasized by the author.\\n\"\n",
    "            \"## Response Format\\n\"\n",
    "            \"For each quote, include an explanation of its importance in this format:\\n\\n\"\n",
    "            \"> 'Quote text here'\\n\\n\"\n",
    "            \"**Explanation**: why this quote is important\\n\\n\"\n",
    "            \"## Requirements\\n\"\n",
    "            \"- Limit to three critical quotes only.\\n\"\n",
    "            \"- Quotes should be very critical or insightful or innovative.\\n\"\n",
    "            \"- If the title is related to Abstract, References or Conclusion, return 'NO_QUOTES'.\\n\"\n",
    "            \"- If the entire section is unimportant, return 'NO_QUOTES'\",\n",
    "        ),\n",
    "        (\"user\", \"## Title: {title}\\nContent:\\n```\\n{text}\\n```\"),\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "    def extract_section_quotes(self, text: str, title: str) -> str: ...  # type: ignore[empty-body]\n",
    "\n",
    "    def summarize_images(self, base64_img: str, section_summary: str) -> str:\n",
    "        content = []\n",
    "        content += [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Given the image of an paper, explain the key insights and findings from the image.\",\n",
    "            }\n",
    "        ]\n",
    "        content += [{\"type\": \"text\", \"text\": section_summary}]\n",
    "        content += [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}}]  # type: ignore\n",
    "\n",
    "        response = self.llm.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {  # type: ignore\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": content,\n",
    "                }\n",
    "            ],\n",
    "        )  # type: ignore\n",
    "        return response.choices[0].message.content  # type: ignore\n",
    "\n",
    "    @openai_prompt(\n",
    "        (\"system\", \"You are an AI research assistant.\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"## Task\\n\"\n",
    "            \"Organize the provided section summary, and image summaries into a structured format with bullet points:\\n\\n\"\n",
    "            \"- Display each line of the summary as a bullet point.\\n\\n\"\n",
    "            \"- Include the image summary as a bullet point if it not empty.\\n\\n\",\n",
    "        ),\n",
    "        (\"user\", \"Section Summary: ```{summary}```\"),\n",
    "        (\"user\", \"Image Summary: ```{image_summary}```\"),\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "    def organize_section_summary(self, summary: str, image_summary: list[str]): ...  # type: ignore[empty-body]\n",
    "\n",
    "    @openai_prompt(\n",
    "        (\"system\", \"You are an AI research assistant.\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"I am reading deep learning and AI research papers and need structured notes based on specific sections of the content. \"\n",
    "            \"For each section provided, focus on the following points:\\n\\n\"\n",
    "            \"### Problem\\n\"\n",
    "            \"- What problem does this paper aim to solve?\\n\"\n",
    "            \"- What are the existing methods, and what limitations do they have?\\n\\n\"\n",
    "            \"### Solution\\n\"\n",
    "            \"- What solution does the paper propose?\\n\"\n",
    "            \"- What inspired this idea? Was it influenced by other papers?\\n\"\n",
    "            \"- What theoretical basis supports this method?\\n\\n\"\n",
    "            \"### Experiment\\n\"\n",
    "            \"- How well does the experiment perform?\\n\"\n",
    "            \"- What limitations or assumptions are associated with this method?\\n\\n\"\n",
    "            \"### Innovation\\n\"\n",
    "            \"- What important or novel discoveries does this paper make?\\n\\n\"\n",
    "            \"### Comments / Critique\\n\"\n",
    "            \"- Are there any limitations in this paper?\\n\"\n",
    "            \"- Does the paper substantiate its claims effectively?\\n\\n\"\n",
    "            \"Do NOT include any content outside this format.\\n\",\n",
    "        ),\n",
    "        (\"user\", \"Section Content: ```{text}```\"),\n",
    "        model_name=\"gpt-4o\",\n",
    "    )\n",
    "    def _extract_keynote(self, text: str) -> str: ...  # type: ignore[empty-body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/abs/2410.22366\"\n",
    "paper_summarizer = ArxivPaperSummarizer(arxiv_url=arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for list[ExtractedSectionResult]\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summary_result \u001b[38;5;241m=\u001b[39m \u001b[43mpaper_summarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary_result)\n",
      "Cell \u001b[0;32mIn[3], line 59\u001b[0m, in \u001b[0;36mArxivPaperSummarizer.summarize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SummaryResult:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Summarize the arXiv paper.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     section_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_section_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     section_info_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_section_info_list(section_list)\n\u001b[1;32m     61\u001b[0m     keynote \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_keynote()\n",
      "Cell \u001b[0;32mIn[3], line 201\u001b[0m, in \u001b[0;36mArxivPaperSummarizer.extract_section_list\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    199\u001b[0m json_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_paper_sections(text)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    200\u001b[0m json_obj \u001b[38;5;241m=\u001b[39m extract_json_content(json_str)\n\u001b[0;32m--> 201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTypeAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mExtractedSectionResult\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev-personal/arxiv-paper-summarizer/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:135\u001b[0m, in \u001b[0;36m_frame_depth.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m: TypeAdapterT, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m R:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_frame_depth(depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# depth + 1 for the wrapper function\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev-personal/arxiv-paper-summarizer/.venv/lib/python3.12/site-packages/pydantic/type_adapter.py:366\u001b[0m, in \u001b[0;36mTypeAdapter.validate_python\u001b[0;34m(self, object, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;129m@_frame_depth\u001b[39m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_python\u001b[39m(\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m     context: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    350\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate a Python object against the model.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m        The validated object.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for list[ExtractedSectionResult]\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.9/v/list_type"
     ]
    }
   ],
   "source": [
    "summary_result = paper_summarizer.summarize()\n",
    "print(summary_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
